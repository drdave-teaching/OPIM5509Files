{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/drdave-teaching/OPIM5509Files/blob/main/OPIM5509_Module2_Files/2_A_FirstLook_atNN(with_MNIST_images).ipynb)"
      ],
      "metadata": {
        "id": "Xe-phqQZcYOd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80y2_zhbjcd9"
      },
      "source": [
        "# A First Look at a NN with MNIST images\n",
        "------------------------------\n",
        "**Dr. Dave Wanik**\n",
        "\n",
        "This notebook contains the code samples found in Chapter 2, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
        "\n",
        "----\n",
        "\n",
        "We will now take a look at a first concrete example of a neural network, which makes use of the Python library Keras to learn to classify\n",
        "hand-written digits. Unless you already have experience with Keras or similar libraries, you will not understand everything about this\n",
        "first example right away. You probably haven't even installed Keras yet. Don't worry, that is perfectly fine. In the next chapter, we will\n",
        "review each element in our example and explain them in detail. So don't worry if some steps seem arbitrary or look like magic to you!\n",
        "We've got to start somewhere.\n",
        "\n",
        "The problem we are trying to solve here is to classify grayscale images of handwritten digits (28 pixels by 28 pixels), into their 10\n",
        "categories (0 to 9). The dataset we will use is the MNIST dataset, a classic dataset in the machine learning community, which has been\n",
        "around for almost as long as the field itself and has been very intensively studied. It's a set of 60,000 training images, plus 10,000 test\n",
        "images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s. You can think of \"solving\" MNIST\n",
        "as the \"Hello World\" of deep learning -- it's what you do to verify that your algorithms are working as expected. As you become a machine\n",
        "learning practitioner, you will see MNIST come up over and over again, in scientific papers, blog posts, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3hpfsz8jcd9"
      },
      "source": [
        "The MNIST dataset comes pre-loaded in Keras, in the form of a set of four Numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXP0bOStjcd-",
        "outputId": "03f873b9-95c0-447e-f2cc-bab3d92ef9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqb3khkljceC"
      },
      "source": [
        "`train_images` and `train_labels` form the \"training set\", the data that the model will learn from. The model will then be tested on the\n",
        "\"test set\", `test_images` and `test_labels`. Our images are encoded as Numpy arrays, and the labels are simply an array of digits, ranging\n",
        "from 0 to 9. There is a one-to-one correspondence between the images and the labels.\n",
        "\n",
        "Let's have a look at the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOa0EUQqjceD",
        "outputId": "8d73a49e-4f69-4dbe-8fcf-8f718b50e074"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIcI5aa0jceF",
        "outputId": "77c71dce-3b6e-4e06-9bbc-5741b98123aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n8Hqgi1jceI",
        "outputId": "ce38c8ad-47f0-4ae6-baa3-81809747a1e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJArl17GXgjr",
        "outputId": "15c43221-fa3b-410d-c37b-52c25821c4e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    6742\n",
              "7    6265\n",
              "3    6131\n",
              "2    5958\n",
              "9    5949\n",
              "0    5923\n",
              "6    5918\n",
              "8    5851\n",
              "4    5842\n",
              "5    5421\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tmp = train_labels\n",
        "import pandas as pd\n",
        "tmp = pd.DataFrame(tmp)\n",
        "tmp[0].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OydGZhFglx7Z"
      },
      "source": [
        "## Look at one image...\n",
        "Just to get a feel for the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "YP07k0Q5j8mH",
        "outputId": "9a4b5b2f-69c0-48de-8ab2-c1950dd4347d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    0   1   2   3    4    5    6    7    8    9   ...   18   19   20   21  \\\n",
              "0    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "1    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "2    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "3    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "4    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "5    0   0   0   0    0    0    0    0    0    0  ...  175   26  166  255   \n",
              "6    0   0   0   0    0    0    0    0   30   36  ...  225  172  253  242   \n",
              "7    0   0   0   0    0    0    0   49  238  253  ...   93   82   82   56   \n",
              "8    0   0   0   0    0    0    0   18  219  253  ...    0    0    0    0   \n",
              "9    0   0   0   0    0    0    0    0   80  156  ...    0    0    0    0   \n",
              "10   0   0   0   0    0    0    0    0    0   14  ...    0    0    0    0   \n",
              "11   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "12   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "13   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "14   0   0   0   0    0    0    0    0    0    0  ...   25    0    0    0   \n",
              "15   0   0   0   0    0    0    0    0    0    0  ...  150   27    0    0   \n",
              "16   0   0   0   0    0    0    0    0    0    0  ...  253  187    0    0   \n",
              "17   0   0   0   0    0    0    0    0    0    0  ...  253  249   64    0   \n",
              "18   0   0   0   0    0    0    0    0    0    0  ...  253  207    2    0   \n",
              "19   0   0   0   0    0    0    0    0    0    0  ...  250  182    0    0   \n",
              "20   0   0   0   0    0    0    0    0    0    0  ...   78    0    0    0   \n",
              "21   0   0   0   0    0    0    0    0   23   66  ...    0    0    0    0   \n",
              "22   0   0   0   0    0    0   18  171  219  253  ...    0    0    0    0   \n",
              "23   0   0   0   0   55  172  226  253  253  253  ...    0    0    0    0   \n",
              "24   0   0   0   0  136  253  253  253  212  135  ...    0    0    0    0   \n",
              "25   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "26   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "27   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "\n",
              "     22   23  24  25  26  27  \n",
              "0     0    0   0   0   0   0  \n",
              "1     0    0   0   0   0   0  \n",
              "2     0    0   0   0   0   0  \n",
              "3     0    0   0   0   0   0  \n",
              "4     0    0   0   0   0   0  \n",
              "5   247  127   0   0   0   0  \n",
              "6   195   64   0   0   0   0  \n",
              "7    39    0   0   0   0   0  \n",
              "8     0    0   0   0   0   0  \n",
              "9     0    0   0   0   0   0  \n",
              "10    0    0   0   0   0   0  \n",
              "11    0    0   0   0   0   0  \n",
              "12    0    0   0   0   0   0  \n",
              "13    0    0   0   0   0   0  \n",
              "14    0    0   0   0   0   0  \n",
              "15    0    0   0   0   0   0  \n",
              "16    0    0   0   0   0   0  \n",
              "17    0    0   0   0   0   0  \n",
              "18    0    0   0   0   0   0  \n",
              "19    0    0   0   0   0   0  \n",
              "20    0    0   0   0   0   0  \n",
              "21    0    0   0   0   0   0  \n",
              "22    0    0   0   0   0   0  \n",
              "23    0    0   0   0   0   0  \n",
              "24    0    0   0   0   0   0  \n",
              "25    0    0   0   0   0   0  \n",
              "26    0    0   0   0   0   0  \n",
              "27    0    0   0   0   0   0  \n",
              "\n",
              "[28 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08f2f479-32d1-4a1f-a3f5-06461a11380a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>175</td>\n",
              "      <td>26</td>\n",
              "      <td>166</td>\n",
              "      <td>255</td>\n",
              "      <td>247</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>225</td>\n",
              "      <td>172</td>\n",
              "      <td>253</td>\n",
              "      <td>242</td>\n",
              "      <td>195</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>238</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>93</td>\n",
              "      <td>82</td>\n",
              "      <td>82</td>\n",
              "      <td>56</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>219</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>156</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>249</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>253</td>\n",
              "      <td>207</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>250</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>66</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>171</td>\n",
              "      <td>219</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>172</td>\n",
              "      <td>226</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>212</td>\n",
              "      <td>135</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08f2f479-32d1-4a1f-a3f5-06461a11380a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08f2f479-32d1-4a1f-a3f5-06461a11380a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08f2f479-32d1-4a1f-a3f5-06461a11380a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# look at one image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# subset first 'image'\n",
        "x = train_images[0]\n",
        "# convert to pandas dataframe for easy viewing...\n",
        "x = pd.DataFrame(x)\n",
        "print(x.shape) # 28 rows and 28 columns\n",
        "# you can confirm\n",
        "print(train_labels[0])\n",
        "x # it's the number 5!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFO0uvafjceL"
      },
      "source": [
        "Let's have a look at the test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6SYScQcjceM",
        "outputId": "75cb4a8c-e46f-4b4d-924a-0e532ff15e33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tdz8MKpjceP",
        "outputId": "35e9e490-035f-4441-dac9-9854e3deeaf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXUC6KQajceU",
        "outputId": "14cab18e-b9d8-4806-e824-0f84942383e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_labels[0:10] # just a sample of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v72T0A3dZNmD",
        "outputId": "210d80a9-62f8-4661-95e5-87cc184a96c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1135\n",
              "2    1032\n",
              "7    1028\n",
              "3    1010\n",
              "9    1009\n",
              "4     982\n",
              "0     980\n",
              "8     974\n",
              "6     958\n",
              "5     892\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# check out value counts\n",
        "tmp = test_labels\n",
        "import pandas as pd\n",
        "tmp = pd.DataFrame(tmp)\n",
        "tmp[0].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQtiTsOIw-Dp"
      },
      "outputs": [],
      "source": [
        "# making a copy for later (logistic regression)\n",
        "copy_train_labels = train_labels\n",
        "copy_test_labels = test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8WwVfLjceX"
      },
      "source": [
        "Our workflow will be as follow: first we will present our neural network with the training data, `train_images` and `train_labels`. The\n",
        "network will then learn to associate images and labels. Finally, we will ask the network to produce predictions for `test_images`, and we\n",
        "will verify if these predictions match the labels from `test_labels`.\n",
        "\n",
        "Let's build our network -- again, remember that you aren't supposed to understand everything about this example just yet."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "28*28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rd7S3pp4uhL",
        "outputId": "17792688-5405-4dab-b4bd-9fada4502976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bPKpXZJjceX",
        "outputId": "62d17947-16b9-4795-f8c8-525d150a2e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(Dense(784, activation='relu', input_shape=(28 * 28,))) # (features, )\n",
        "network.add(Dense(10, activation='softmax'))\n",
        "network.summary()\n",
        "\n",
        "# note: input shape is the trickiest part IMHO...\n",
        "# think of it as (number of columns, number of samples)\n",
        "# number of samples is ALWAYS left blank (you'll set the batch size later on!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RpleqSajceb"
      },
      "source": [
        "\n",
        "The core building block of neural networks is the \"layer\", a data-processing module which you can conceive as a \"filter\" for data. Some\n",
        "data comes in, and comes out in a more useful form. Precisely, layers extract _representations_ out of the data fed into them -- hopefully\n",
        "representations that are more meaningful for the problem at hand. Most of deep learning really consists of chaining together simple layers\n",
        "which will implement a form of progressive \"data distillation\". A deep learning model is like a sieve for data processing, made of a\n",
        "succession of increasingly refined data filters -- the \"layers\".\n",
        "\n",
        "Here our network consists of a sequence of two `Dense` layers, which are densely-connected (also called \"fully-connected\") neural layers.\n",
        "The second (and last) layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each\n",
        "score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
        "\n",
        "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
        "\n",
        "* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be\n",
        "able to steer itself in the right direction.\n",
        "* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
        "* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly\n",
        "classified).\n",
        "\n",
        "The exact purpose of the loss function and the optimizer will be made clear throughout the next two chapters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHzWKWCKjcec"
      },
      "outputs": [],
      "source": [
        "network.compile(optimizer='rmsprop', # you could use rmsprop or Adam - both are good!\n",
        "                loss='categorical_crossentropy', # many categories - you need to use 'categorical_crossentropy' and NOT 'binary_crossentropy'\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArMRcF1Kjcef"
      },
      "source": [
        "\n",
        "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in\n",
        "the `[0, 1]` interval. Previously, our training images for instance were stored in an array of shape `(60000, 28, 28)` of type `uint8` with\n",
        "values in the `[0, 255]` interval. We transform it into a `float32` array of shape `(60000, 28 * 28)` with values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7K3v0n9aJa-",
        "outputId": "0a91caa2-4795-42c9-c09f-fb12b5209324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "28*28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU_x8YWXjceg"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28)) # 60K rows, with 784 columns... wow!\n",
        "train_images = train_images.astype('float32') / 255 # here we are scaling by max pixel value (where white =255, black = 0)\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gil6-5rsmR61",
        "outputId": "248c8f92-f235-4a79-bb68-7654a4154ac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
              "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
              "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
              "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
              "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
              "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
              "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
              "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
              "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
              "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
              "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
              "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
              "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
              "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
              "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# BE CURIOUS!\n",
        "# see what the model did\n",
        "x = train_images[0] # instead of a 2D array that is 28*28, it's a single row!\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "WT8xE47SmqDP",
        "outputId": "62c3641a-9182-4a3f-caa5-8c0416962c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   778  779  780  781  782  783  \n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "5  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "6  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "7  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "8  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "9  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[10 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a0cd0b9-b48a-4477-82c2-80b47e43758a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a0cd0b9-b48a-4477-82c2-80b47e43758a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a0cd0b9-b48a-4477-82c2-80b47e43758a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a0cd0b9-b48a-4477-82c2-80b47e43758a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# you can see this in the entire dataset too\n",
        "x = pd.DataFrame(train_images)\n",
        "print(x.shape)\n",
        "print(28*28) # see how the shape matches up?\n",
        "x.head(n=10)\n",
        "\n",
        "# that first sample is now just the first row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzPHYJzojcek"
      },
      "source": [
        "We also need to categorically encode the labels, a step which we explain in chapter 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkDTT9AUjcek"
      },
      "outputs": [],
      "source": [
        "# from keras.utils import to_categorical # this is the old code!\n",
        "from tensorflow.keras.utils import to_categorical  # this is the new way!\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQxcJD3UnIgB",
        "outputId": "7a775b38-2715-4cde-ac71-f7c89a1df7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# BE CURIOUS! See what it looks like\n",
        "x = train_labels[0]\n",
        "print(x)\n",
        "# check out the output - the first sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "h0VjOu8evA9N",
        "outputId": "a16b2a4e-6a88-477e-a9b5-e24a83aec2e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0    1    2    3    4    5    6    7    8    9\n",
              "0      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "1      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2      0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
              "3      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
              "59996  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "59997  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "59998  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
              "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
              "\n",
              "[60000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9253af58-3b59-4304-a552-a3edf368e697\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9253af58-3b59-4304-a552-a3edf368e697')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9253af58-3b59-4304-a552-a3edf368e697 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9253af58-3b59-4304-a552-a3edf368e697');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# check them ALL out!\n",
        "x = train_labels\n",
        "x = pd.DataFrame(x)\n",
        "x\n",
        "\n",
        "# so the labels are in an ARRAY with one column for each potential outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avhwTrw-jcem"
      },
      "source": [
        "We are now ready to train our network, which in Keras is done via a call to the `fit` method of the network:\n",
        "we \"fit\" the model to its training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDVcHvbYjcen",
        "outputId": "6d287405-38f5-48d0-f6b7-19ba7b82db48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "375/375 [==============================] - 4s 8ms/step - loss: 0.2710 - accuracy: 0.9198 - val_loss: 0.1437 - val_accuracy: 0.9579\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1064 - accuracy: 0.9687 - val_loss: 0.0950 - val_accuracy: 0.9722\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0698 - accuracy: 0.9788 - val_loss: 0.0807 - val_accuracy: 0.9742\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0482 - accuracy: 0.9850 - val_loss: 0.0807 - val_accuracy: 0.9754\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0352 - accuracy: 0.9895 - val_loss: 0.0834 - val_accuracy: 0.9762\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.0850 - val_accuracy: 0.9776\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0858 - val_accuracy: 0.9772\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0858 - val_accuracy: 0.9795\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0934 - val_accuracy: 0.9789\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0871 - val_accuracy: 0.9808\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0937 - val_accuracy: 0.9808\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1019 - val_accuracy: 0.9798\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1061 - val_accuracy: 0.9794\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1115 - val_accuracy: 0.9793\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1139 - val_accuracy: 0.9807\n"
          ]
        }
      ],
      "source": [
        "history = network.fit(train_images, train_labels, epochs=15, batch_size=128, validation_split=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgJN08f9jceq"
      },
      "source": [
        "Two quantities are being displayed during training: the \"loss\" of the network over the training data, and the accuracy of the network over\n",
        "the training data.\n",
        "\n",
        "We quickly reach an accuracy of 0.989 (i.e. 98.9%) on the training data. Now let's check that our model performs well on the test set too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2M3j05Ojceq",
        "outputId": "3c89e525-f1e8-414d-8818-d047bf3c8c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9819\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVotbKXVjces",
        "outputId": "64b1d9e1-15e8-4860-93f7-06f2d6d78097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.9818999767303467\n"
          ]
        }
      ],
      "source": [
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJU8th_xjcev"
      },
      "source": [
        "\n",
        "Our test set accuracy turns out to be ~98% -- that's quite a bit lower than the training set accuracy.\n",
        "This gap between training accuracy and test accuracy is an example of \"overfitting\",\n",
        "the fact that machine learning models tend to perform worse on new data than on their training data.\n",
        "Overfitting will be a central topic in chapter 3.\n",
        "\n",
        "This concludes our very first example -- you just saw how we could build and a train a neural network to classify handwritten digits, in\n",
        "less than 20 lines of Python code. In the next chapter, we will go in detail over every moving piece we just previewed, and clarify what is really\n",
        "going on behind the scenes. You will learn about \"tensors\", the data-storing objects going into the network, about tensor operations, which\n",
        "layers are made of, and about gradient descent, which allows our network to learn from its training examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGiUc2ruvWBK"
      },
      "source": [
        "## Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AbWZYQdGvZcO",
        "outputId": "9743ef0f-87d1-4a46-880d-9f066841fc58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# show what the predictions look like for a multi-class classification problem\n",
        "# pretty!\n",
        "\n",
        "# learning curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"r\" is for \"solid red line\"\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu2m4Q-kwKsN",
        "outputId": "a8b46287-d1e9-4481-ef70-e055aabd1846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 971,    0,    1,    0,    1,    1,    3,    1,    2,    0],\n",
              "       [   0, 1129,    2,    0,    0,    1,    2,    0,    1,    0],\n",
              "       [   3,    0, 1007,    6,    3,    0,    2,    4,    7,    0],\n",
              "       [   1,    0,    0,  997,    0,    5,    0,    2,    1,    4],\n",
              "       [   1,    0,    1,    1,  963,    0,    3,    3,    2,    8],\n",
              "       [   2,    0,    0,    7,    1,  876,    2,    0,    2,    2],\n",
              "       [   3,    3,    1,    1,    3,    3,  944,    0,    0,    0],\n",
              "       [   1,    4,    8,    4,    0,    0,    0, 1000,    3,    8],\n",
              "       [   2,    1,    3,    5,    3,    4,    1,    2,  948,    5],\n",
              "       [   2,    3,    0,    4,    5,    5,    0,    3,    3,  984]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# see how the model did!\n",
        "preds = network.predict(test_images)\n",
        "preds # if you look at preds, there's actually a probability in there...\n",
        "\n",
        "# here it is! almost a perfect prediction\n",
        "# actual is left, predicted is top\n",
        "# names can be found by inspecting Y\n",
        "matrix = confusion_matrix(test_labels.argmax(axis=1), preds.argmax(axis=1))\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5ylyOkwUVz",
        "outputId": "bd5b4abf-7af1-4bae-c4b2-e422ca1fa8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.97      0.98      1032\n",
            "           3       0.97      0.99      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.97      0.98       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.98      0.98      0.98      1028\n",
            "           8       0.97      0.98      0.98       974\n",
            "           9       0.98      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels.argmax(axis=1), preds.argmax(axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "951y8ZInuvb9"
      },
      "source": [
        "# Try a Baseline Model for Fun\n",
        "Just to show the power on DNNs, why not try a more familiar model like logistic regression? Because it's less accurate and actually takes MORE time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOiiB6Yhwm2m"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(max_iter=100000000)\n",
        "\n",
        "# warning: takes a long time to fit!\n",
        "\n",
        "# had to make a copy of the labels because it expects a 1D array,\n",
        "# not like the previous to_categorical() we used.\n",
        "clf = LR.fit(train_images, # X\n",
        "             copy_train_labels) # y (stored in original 5, 6, 7, 9 format... original labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viY0yzAvyHbE",
        "outputId": "126cb332-f1cd-4864-ac17-1873e28dc9e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 955,    0,    2,    4,    1,   10,    4,    3,    1,    0],\n",
              "       [   0, 1110,    5,    2,    0,    2,    3,    2,   11,    0],\n",
              "       [   6,    9,  930,   14,   10,    3,   12,   10,   34,    4],\n",
              "       [   4,    1,   16,  925,    1,   23,    2,   10,   19,    9],\n",
              "       [   1,    3,    7,    3,  921,    0,    6,    5,    6,   30],\n",
              "       [   9,    2,    3,   35,   10,  777,   15,    6,   31,    4],\n",
              "       [   8,    3,    8,    2,    6,   16,  912,    2,    1,    0],\n",
              "       [   1,    7,   23,    7,    6,    1,    0,  947,    4,   32],\n",
              "       [   9,   11,    6,   22,    7,   29,   13,   10,  855,   12],\n",
              "       [   9,    8,    1,    9,   21,    7,    0,   21,    9,  924]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# evaluate confusion matrix\n",
        "preds = clf.predict(test_images)\n",
        "\n",
        "confusion_matrix(copy_test_labels, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuLU56SpyJdZ",
        "outputId": "8064684b-b2f3-4b2f-8e66-35b15ac39a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.93      0.90      0.91      1032\n",
            "           3       0.90      0.92      0.91      1010\n",
            "           4       0.94      0.94      0.94       982\n",
            "           5       0.90      0.87      0.88       892\n",
            "           6       0.94      0.95      0.95       958\n",
            "           7       0.93      0.92      0.93      1028\n",
            "           8       0.88      0.88      0.88       974\n",
            "           9       0.91      0.92      0.91      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# evaluate train results - it does OK,\n",
        "# but NN does better!\n",
        "\n",
        "print(classification_report(copy_test_labels, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2LbDymaYzFf0"
      },
      "outputs": [],
      "source": [
        "# interpret the output!\n",
        "# what is going on with the number five?\n",
        "# X is predicted, Y is actual"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}