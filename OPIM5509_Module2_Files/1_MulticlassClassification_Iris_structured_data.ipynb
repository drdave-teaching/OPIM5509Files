{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/drdave-teaching/OPIM5509Files/blob/main/OPIM5509_Module2_Files/1_MulticlassClassification_Iris_structured_data.ipynb)"
      ],
      "metadata": {
        "id": "0dmctChhcAX3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Rp37euaxC1"
      },
      "source": [
        "# Dense Neural Networks: Multiclass Classification\n",
        "----------------------------------\n",
        "**Dr. Dave Wanik**\n",
        "\n",
        "Let's try to fit a dense neural network with the Iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBm-P-oBap7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6ee2cf-7c81-4d0a-aae0-9390c9dd5c02"
      },
      "source": [
        "# for reading data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "!pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier # updated 2023\n",
        "\n",
        "# from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# for modeling\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# useful link: https://shrikar.com/deep-learning-with-keras-and-python-for-multiclass-classification/\n",
        "# useful link: https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7mt6w2hbToc"
      },
      "source": [
        "# # read in the data\n",
        "# url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/639388c2cbc2120a14dcf466e85730eb8be498bb/iris.csv'\n",
        "# df = pd.read_csv(url)\n",
        "# df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # read from shareable link\n",
        "# # https://drive.google.com/file/d/1hcnnt2HJ6Iiv6yJJrk0thlPSibu_1q3x/view?usp=sharing\n",
        "# !gdown 1hcnnt2HJ6Iiv6yJJrk0thlPSibu_1q3x\n",
        "# df = pd.read_csv('Iris.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5BbaEhFEUGJ",
        "outputId": "3d18bdfc-35f3-4d30-b34a-9c8b75dad919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hcnnt2HJ6Iiv6yJJrk0thlPSibu_1q3x\n",
            "To: /content/Iris.csv\n",
            "\r  0% 0.00/4.61k [00:00<?, ?B/s]\r100% 4.61k/4.61k [00:00<00:00, 5.08MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to the data file on Github\n",
        "url = \"https://raw.githubusercontent.com/drdave-teaching/OPIM5509Files/refs/heads/main/OPIM5509_Module2_Files/Iris.csv\"\n",
        "\n",
        "# retrieve the data and build a dataframe\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzLrvfWSpbs8",
        "outputId": "6a727e03-c3c6-4705-dbf4-d329de4f7b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kMLXqntbbv2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2c360221-49eb-43d5-d8aa-445315703b77"
      },
      "source": [
        "# show the head\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width         iris\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d97c7c6-8df7-44a8-9a8d-fbaa27148691\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>iris</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d97c7c6-8df7-44a8-9a8d-fbaa27148691')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d97c7c6-8df7-44a8-9a8d-fbaa27148691 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d97c7c6-8df7-44a8-9a8d-fbaa27148691');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldGFRANLq-m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f74b4c0-ce61-4b65-a052-71bf6b589b10"
      },
      "source": [
        "# show counts per species\n",
        "df['iris'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Iris-setosa        50\n",
              "Iris-versicolor    50\n",
              "Iris-virginica     50\n",
              "Name: iris, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcGZp0EKl0RO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "636e2022-876a-466c-f937-7d7a777b5676"
      },
      "source": [
        "# don't forget to shuffle! this way our data has some order...\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()\n",
        "# link: https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width             iris\n",
              "0           5.1          3.8           1.5          0.3      Iris-setosa\n",
              "1           6.7          3.1           4.7          1.5  Iris-versicolor\n",
              "2           5.0          3.2           1.2          0.2      Iris-setosa\n",
              "3           5.6          2.5           3.9          1.1  Iris-versicolor\n",
              "4           7.7          3.8           6.7          2.2   Iris-virginica"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da67be2b-20da-440b-894c-bae3747d28c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>iris</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.1</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.2</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da67be2b-20da-440b-894c-bae3747d28c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da67be2b-20da-440b-894c-bae3747d28c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da67be2b-20da-440b-894c-bae3747d28c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQr22_5odcMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac0ba16-c9c6-437e-94b0-1972772da37d"
      },
      "source": [
        "# split into X and Y\n",
        "Y = df['iris']\n",
        "X = df.drop(['iris'], axis=1)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fHqolEVd2Lr"
      },
      "source": [
        "# convert to numpy arrays\n",
        "X = np.array(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exmvntwjtF2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a21282e-e7f1-4581-f736-a827cb97e79c"
      },
      "source": [
        "# show Y\n",
        "Y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Iris-setosa\n",
              "1    Iris-versicolor\n",
              "2        Iris-setosa\n",
              "3    Iris-versicolor\n",
              "4     Iris-virginica\n",
              "Name: iris, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7GXPcovklGs"
      },
      "source": [
        "# work with labels\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoded_Y = encoder.fit_transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD3DnBFxT9d7",
        "outputId": "0a589601-d8ea-4edc-f629-467b2e96513a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2,\n",
              "       0, 1, 0, 0, 1, 0, 2, 2, 0, 1, 2, 0, 2, 0, 1, 2, 0, 0, 0, 2, 0, 0,\n",
              "       0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 2, 2, 2, 1, 0, 1, 0, 1, 1, 1, 2,\n",
              "       0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 2,\n",
              "       0, 0, 2, 0, 1, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 2, 1, 0, 0, 2, 1,\n",
              "       2, 1, 2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 0, 0, 1, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dummy_y.shape)\n",
        "dummy_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5FOlxAT_ZD",
        "outputId": "fb2f2b04-8ba3-44ff-a079-0124eb8d828d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10FZQ2OebndP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af13a55-3b37-4c16-831c-7c0ffa2993c7"
      },
      "source": [
        "# build a model\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # input shape is (features,)\n",
        "model.add(Dense(3, activation='softmax')) # output\n",
        "model.summary()\n",
        "\n",
        "# make sure in a multiclass problem that you have one output node per target class\n",
        "# and use a 'softmax' activation function which forces your model to split\n",
        "# it's prediction among 3 classes (all adds up to 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                80        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqBOCy6tcmyU"
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', # use rmsprop or Adam\n",
        "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZA82zb7cpHM"
      },
      "source": [
        "# fit the model\n",
        "history = model.fit(X,\n",
        "                    dummy_y,\n",
        "                    epochs=40,\n",
        "                    batch_size=10,\n",
        "                    validation_split=0.2, # last 20% of data used as validation\n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5K-bm3uqft2"
      },
      "source": [
        "## Callbacks (Early Stopping, return best weights, patience)\n",
        "Remember that you will just use early_stopping in the future - no need to hard-code epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq_7Lrfoqk5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c111200a-5e93-4ef8-e0cd-06093b9e351a"
      },
      "source": [
        "# we will keep the same model architecture as before,\n",
        "# but we will make this a little simpler...\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# early stopping callback\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 10 consecutive epochs.\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   mode='min',\n",
        "                                   patience=10, # you can play with this!\n",
        "                                   restore_best_weights=True) # important - otherwise you just return the last weigths...\n",
        "\n",
        "# now we just update our model fit call\n",
        "history = model.fit(X,\n",
        "                    dummy_y,\n",
        "                    callbacks=[es],\n",
        "                    epochs=1000000, # you can set this to a big number!\n",
        "                    batch_size=10,\n",
        "                    shuffle=True,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000000\n",
            "12/12 [==============================] - 1s 24ms/step - loss: 1.9784 - accuracy: 0.0083 - val_loss: 1.8260 - val_accuracy: 0.0333\n",
            "Epoch 2/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6986 - accuracy: 0.0417 - val_loss: 1.5819 - val_accuracy: 0.2000\n",
            "Epoch 3/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5435 - accuracy: 0.2167 - val_loss: 1.4122 - val_accuracy: 0.2000\n",
            "Epoch 4/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4243 - accuracy: 0.2333 - val_loss: 1.2915 - val_accuracy: 0.2667\n",
            "Epoch 5/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3251 - accuracy: 0.2917 - val_loss: 1.1962 - val_accuracy: 0.4333\n",
            "Epoch 6/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.3667 - val_loss: 1.1302 - val_accuracy: 0.5667\n",
            "Epoch 7/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1479 - accuracy: 0.3750 - val_loss: 1.0556 - val_accuracy: 0.5667\n",
            "Epoch 8/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0700 - accuracy: 0.4083 - val_loss: 0.9736 - val_accuracy: 0.4667\n",
            "Epoch 9/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0091 - accuracy: 0.3667 - val_loss: 0.9369 - val_accuracy: 0.4333\n",
            "Epoch 10/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9575 - accuracy: 0.3500 - val_loss: 0.8990 - val_accuracy: 0.4333\n",
            "Epoch 11/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9103 - accuracy: 0.4583 - val_loss: 0.8669 - val_accuracy: 0.6333\n",
            "Epoch 12/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8668 - accuracy: 0.6833 - val_loss: 0.8340 - val_accuracy: 0.7000\n",
            "Epoch 13/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8281 - accuracy: 0.6833 - val_loss: 0.8022 - val_accuracy: 0.7000\n",
            "Epoch 14/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7901 - accuracy: 0.7083 - val_loss: 0.7727 - val_accuracy: 0.8000\n",
            "Epoch 15/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7568 - accuracy: 0.7417 - val_loss: 0.7326 - val_accuracy: 0.7000\n",
            "Epoch 16/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7269 - accuracy: 0.7833 - val_loss: 0.7068 - val_accuracy: 0.7333\n",
            "Epoch 17/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7008 - accuracy: 0.7667 - val_loss: 0.6809 - val_accuracy: 0.7333\n",
            "Epoch 18/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.7083 - val_loss: 0.6778 - val_accuracy: 0.8333\n",
            "Epoch 19/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.7583 - val_loss: 0.6501 - val_accuracy: 0.8000\n",
            "Epoch 20/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.7833 - val_loss: 0.6323 - val_accuracy: 0.8000\n",
            "Epoch 21/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.7583 - val_loss: 0.6364 - val_accuracy: 0.8000\n",
            "Epoch 22/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6050 - accuracy: 0.7667 - val_loss: 0.6183 - val_accuracy: 0.8333\n",
            "Epoch 23/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5883 - accuracy: 0.7917 - val_loss: 0.6138 - val_accuracy: 0.7667\n",
            "Epoch 24/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.8000 - val_loss: 0.5895 - val_accuracy: 0.8667\n",
            "Epoch 25/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.8167 - val_loss: 0.5762 - val_accuracy: 0.8667\n",
            "Epoch 26/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.8417 - val_loss: 0.5645 - val_accuracy: 0.8667\n",
            "Epoch 27/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.8250 - val_loss: 0.5456 - val_accuracy: 0.8667\n",
            "Epoch 28/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.8333 - val_loss: 0.5417 - val_accuracy: 0.9000\n",
            "Epoch 29/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.8417 - val_loss: 0.5403 - val_accuracy: 0.8667\n",
            "Epoch 30/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.8333 - val_loss: 0.5312 - val_accuracy: 0.8667\n",
            "Epoch 31/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4973 - accuracy: 0.8667 - val_loss: 0.5195 - val_accuracy: 0.8667\n",
            "Epoch 32/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8417 - val_loss: 0.5021 - val_accuracy: 0.9000\n",
            "Epoch 33/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.8583 - val_loss: 0.4904 - val_accuracy: 0.9000\n",
            "Epoch 34/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.8500 - val_loss: 0.4921 - val_accuracy: 0.9000\n",
            "Epoch 35/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.8583 - val_loss: 0.4803 - val_accuracy: 0.9000\n",
            "Epoch 36/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.8667 - val_loss: 0.4707 - val_accuracy: 0.9000\n",
            "Epoch 37/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.8500 - val_loss: 0.4777 - val_accuracy: 0.8667\n",
            "Epoch 38/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8750 - val_loss: 0.4639 - val_accuracy: 0.9000\n",
            "Epoch 39/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8750 - val_loss: 0.4556 - val_accuracy: 0.9000\n",
            "Epoch 40/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.8667 - val_loss: 0.4445 - val_accuracy: 0.9333\n",
            "Epoch 41/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8833 - val_loss: 0.4462 - val_accuracy: 0.9000\n",
            "Epoch 42/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8917 - val_loss: 0.4401 - val_accuracy: 0.9000\n",
            "Epoch 43/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8750 - val_loss: 0.4469 - val_accuracy: 0.8667\n",
            "Epoch 44/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8833 - val_loss: 0.4256 - val_accuracy: 0.9333\n",
            "Epoch 45/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.9083 - val_loss: 0.4378 - val_accuracy: 0.8667\n",
            "Epoch 46/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8917 - val_loss: 0.4227 - val_accuracy: 0.9333\n",
            "Epoch 47/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.9000 - val_loss: 0.4081 - val_accuracy: 0.9667\n",
            "Epoch 48/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8833 - val_loss: 0.4317 - val_accuracy: 0.8333\n",
            "Epoch 49/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8667 - val_loss: 0.3979 - val_accuracy: 0.9667\n",
            "Epoch 50/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3724 - accuracy: 0.9083 - val_loss: 0.4027 - val_accuracy: 0.9333\n",
            "Epoch 51/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3667 - accuracy: 0.9083 - val_loss: 0.4183 - val_accuracy: 0.8667\n",
            "Epoch 52/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3636 - accuracy: 0.8917 - val_loss: 0.3873 - val_accuracy: 0.9667\n",
            "Epoch 53/1000000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.9167 - val_loss: 0.3908 - val_accuracy: 0.9667\n",
            "Epoch 54/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.9167 - val_loss: 0.4104 - val_accuracy: 0.8333\n",
            "Epoch 55/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3523 - accuracy: 0.8833 - val_loss: 0.3688 - val_accuracy: 0.9667\n",
            "Epoch 56/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3456 - accuracy: 0.9333 - val_loss: 0.3831 - val_accuracy: 0.9000\n",
            "Epoch 57/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3456 - accuracy: 0.9083 - val_loss: 0.3730 - val_accuracy: 0.9667\n",
            "Epoch 58/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3410 - accuracy: 0.8917 - val_loss: 0.3757 - val_accuracy: 0.9333\n",
            "Epoch 59/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.9250 - val_loss: 0.3710 - val_accuracy: 0.9333\n",
            "Epoch 60/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.9083 - val_loss: 0.3446 - val_accuracy: 1.0000\n",
            "Epoch 61/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3265 - accuracy: 0.9250 - val_loss: 0.3844 - val_accuracy: 0.9000\n",
            "Epoch 62/1000000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3262 - accuracy: 0.9250 - val_loss: 0.3633 - val_accuracy: 0.9333\n",
            "Epoch 63/1000000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3252 - accuracy: 0.9333 - val_loss: 0.3524 - val_accuracy: 0.9667\n",
            "Epoch 64/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.9167 - val_loss: 0.3453 - val_accuracy: 0.9667\n",
            "Epoch 65/1000000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3152 - accuracy: 0.9167 - val_loss: 0.3206 - val_accuracy: 1.0000\n",
            "Epoch 66/1000000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3123 - accuracy: 0.9417 - val_loss: 0.3508 - val_accuracy: 0.9333\n",
            "Epoch 67/1000000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3105 - accuracy: 0.9083 - val_loss: 0.3245 - val_accuracy: 1.0000\n",
            "Epoch 68/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3058 - accuracy: 0.9417 - val_loss: 0.3436 - val_accuracy: 0.9333\n",
            "Epoch 69/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3058 - accuracy: 0.9333 - val_loss: 0.3378 - val_accuracy: 0.9333\n",
            "Epoch 70/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3017 - accuracy: 0.9167 - val_loss: 0.3202 - val_accuracy: 1.0000\n",
            "Epoch 71/1000000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2945 - accuracy: 0.9333 - val_loss: 0.3172 - val_accuracy: 1.0000\n",
            "Epoch 72/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2919 - accuracy: 0.9417 - val_loss: 0.3282 - val_accuracy: 0.9333\n",
            "Epoch 73/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2871 - accuracy: 0.9083 - val_loss: 0.2996 - val_accuracy: 1.0000\n",
            "Epoch 74/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2878 - accuracy: 0.9333 - val_loss: 0.3068 - val_accuracy: 1.0000\n",
            "Epoch 75/1000000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.2811 - accuracy: 0.9333 - val_loss: 0.2887 - val_accuracy: 1.0000\n",
            "Epoch 76/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2786 - accuracy: 0.9417 - val_loss: 0.2981 - val_accuracy: 1.0000\n",
            "Epoch 77/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2745 - accuracy: 0.9333 - val_loss: 0.3078 - val_accuracy: 0.9333\n",
            "Epoch 78/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2719 - accuracy: 0.9333 - val_loss: 0.2910 - val_accuracy: 1.0000\n",
            "Epoch 79/1000000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.2671 - accuracy: 0.9250 - val_loss: 0.2698 - val_accuracy: 1.0000\n",
            "Epoch 80/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2656 - accuracy: 0.9333 - val_loss: 0.2892 - val_accuracy: 0.9667\n",
            "Epoch 81/1000000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2608 - accuracy: 0.9250 - val_loss: 0.2822 - val_accuracy: 1.0000\n",
            "Epoch 82/1000000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.2569 - accuracy: 0.9250 - val_loss: 0.2724 - val_accuracy: 1.0000\n",
            "Epoch 83/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2553 - accuracy: 0.9333 - val_loss: 0.2519 - val_accuracy: 1.0000\n",
            "Epoch 84/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2545 - accuracy: 0.9250 - val_loss: 0.2494 - val_accuracy: 1.0000\n",
            "Epoch 85/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2490 - accuracy: 0.9500 - val_loss: 0.2686 - val_accuracy: 1.0000\n",
            "Epoch 86/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2490 - accuracy: 0.9250 - val_loss: 0.2580 - val_accuracy: 1.0000\n",
            "Epoch 87/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2429 - accuracy: 0.9333 - val_loss: 0.2387 - val_accuracy: 1.0000\n",
            "Epoch 88/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2429 - accuracy: 0.9417 - val_loss: 0.2473 - val_accuracy: 1.0000\n",
            "Epoch 89/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2368 - accuracy: 0.9333 - val_loss: 0.2254 - val_accuracy: 1.0000\n",
            "Epoch 90/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2386 - accuracy: 0.9500 - val_loss: 0.2401 - val_accuracy: 1.0000\n",
            "Epoch 91/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2352 - accuracy: 0.9333 - val_loss: 0.2456 - val_accuracy: 1.0000\n",
            "Epoch 92/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2298 - accuracy: 0.9417 - val_loss: 0.2381 - val_accuracy: 1.0000\n",
            "Epoch 93/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.9417 - val_loss: 0.2509 - val_accuracy: 0.9667\n",
            "Epoch 94/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2253 - accuracy: 0.9417 - val_loss: 0.2261 - val_accuracy: 1.0000\n",
            "Epoch 95/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2237 - accuracy: 0.9417 - val_loss: 0.2124 - val_accuracy: 1.0000\n",
            "Epoch 96/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2247 - accuracy: 0.9417 - val_loss: 0.2237 - val_accuracy: 1.0000\n",
            "Epoch 97/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2219 - accuracy: 0.9333 - val_loss: 0.2113 - val_accuracy: 1.0000\n",
            "Epoch 98/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9500 - val_loss: 0.2141 - val_accuracy: 1.0000\n",
            "Epoch 99/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2167 - accuracy: 0.9500 - val_loss: 0.2185 - val_accuracy: 1.0000\n",
            "Epoch 100/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2117 - accuracy: 0.9583 - val_loss: 0.2412 - val_accuracy: 0.9667\n",
            "Epoch 101/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2110 - accuracy: 0.9500 - val_loss: 0.2078 - val_accuracy: 1.0000\n",
            "Epoch 102/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2092 - accuracy: 0.9417 - val_loss: 0.2335 - val_accuracy: 0.9667\n",
            "Epoch 103/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2061 - accuracy: 0.9500 - val_loss: 0.2175 - val_accuracy: 1.0000\n",
            "Epoch 104/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2047 - accuracy: 0.9500 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
            "Epoch 105/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2028 - accuracy: 0.9500 - val_loss: 0.2027 - val_accuracy: 1.0000\n",
            "Epoch 106/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2014 - accuracy: 0.9500 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
            "Epoch 107/1000000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.2043 - accuracy: 0.9500 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
            "Epoch 108/1000000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1992 - accuracy: 0.9500 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
            "Epoch 109/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1955 - accuracy: 0.9500 - val_loss: 0.1880 - val_accuracy: 1.0000\n",
            "Epoch 110/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1919 - accuracy: 0.9500 - val_loss: 0.1914 - val_accuracy: 1.0000\n",
            "Epoch 111/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1947 - accuracy: 0.9417 - val_loss: 0.1886 - val_accuracy: 1.0000\n",
            "Epoch 112/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1933 - accuracy: 0.9500 - val_loss: 0.1913 - val_accuracy: 1.0000\n",
            "Epoch 113/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1885 - accuracy: 0.9500 - val_loss: 0.2006 - val_accuracy: 0.9667\n",
            "Epoch 114/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1880 - accuracy: 0.9583 - val_loss: 0.2045 - val_accuracy: 0.9667\n",
            "Epoch 115/1000000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1867 - accuracy: 0.9417 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
            "Epoch 116/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.9500 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
            "Epoch 117/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1846 - accuracy: 0.9500 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
            "Epoch 118/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1804 - accuracy: 0.9500 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
            "Epoch 119/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1813 - accuracy: 0.9583 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
            "Epoch 120/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1776 - accuracy: 0.9500 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
            "Epoch 121/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1786 - accuracy: 0.9500 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
            "Epoch 122/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1764 - accuracy: 0.9500 - val_loss: 0.1825 - val_accuracy: 0.9667\n",
            "Epoch 123/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1742 - accuracy: 0.9500 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
            "Epoch 124/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.9500 - val_loss: 0.1619 - val_accuracy: 1.0000\n",
            "Epoch 125/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1759 - accuracy: 0.9500 - val_loss: 0.1626 - val_accuracy: 1.0000\n",
            "Epoch 126/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 0.9583 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
            "Epoch 127/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1682 - accuracy: 0.9500 - val_loss: 0.1663 - val_accuracy: 1.0000\n",
            "Epoch 128/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1668 - accuracy: 0.9500 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
            "Epoch 129/1000000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1689 - accuracy: 0.9583 - val_loss: 0.1611 - val_accuracy: 1.0000\n",
            "Epoch 130/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1649 - accuracy: 0.9417 - val_loss: 0.1479 - val_accuracy: 1.0000\n",
            "Epoch 131/1000000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1645 - accuracy: 0.9500 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
            "Epoch 132/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9500 - val_loss: 0.1627 - val_accuracy: 1.0000\n",
            "Epoch 133/1000000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1638 - accuracy: 0.9417 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
            "Epoch 134/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1619 - accuracy: 0.9500 - val_loss: 0.1615 - val_accuracy: 0.9667\n",
            "Epoch 135/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1590 - accuracy: 0.9333 - val_loss: 0.1308 - val_accuracy: 1.0000\n",
            "Epoch 136/1000000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1614 - accuracy: 0.9500 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
            "Epoch 137/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1575 - accuracy: 0.9500 - val_loss: 0.1506 - val_accuracy: 1.0000\n",
            "Epoch 138/1000000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1561 - accuracy: 0.9417 - val_loss: 0.1346 - val_accuracy: 1.0000\n",
            "Epoch 139/1000000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.9500 - val_loss: 0.1293 - val_accuracy: 1.0000\n",
            "Epoch 140/1000000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1559 - accuracy: 0.9500 - val_loss: 0.1337 - val_accuracy: 1.0000\n",
            "Epoch 141/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1555 - accuracy: 0.9417 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
            "Epoch 142/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9583 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
            "Epoch 143/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9583 - val_loss: 0.1534 - val_accuracy: 0.9667\n",
            "Epoch 144/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1494 - accuracy: 0.9417 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
            "Epoch 145/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1479 - accuracy: 0.9583 - val_loss: 0.1360 - val_accuracy: 1.0000\n",
            "Epoch 146/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1504 - accuracy: 0.9583 - val_loss: 0.1472 - val_accuracy: 0.9667\n",
            "Epoch 147/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9417 - val_loss: 0.1115 - val_accuracy: 1.0000\n",
            "Epoch 148/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9500 - val_loss: 0.1262 - val_accuracy: 1.0000\n",
            "Epoch 149/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9583 - val_loss: 0.1473 - val_accuracy: 0.9667\n",
            "Epoch 150/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9500 - val_loss: 0.1067 - val_accuracy: 1.0000\n",
            "Epoch 151/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.9500 - val_loss: 0.1106 - val_accuracy: 1.0000\n",
            "Epoch 152/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9750 - val_loss: 0.1413 - val_accuracy: 0.9667\n",
            "Epoch 153/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9500 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
            "Epoch 154/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.9500 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
            "Epoch 155/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1402 - accuracy: 0.9500 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
            "Epoch 156/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9333 - val_loss: 0.1080 - val_accuracy: 1.0000\n",
            "Epoch 157/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9583 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
            "Epoch 158/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9583 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
            "Epoch 159/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9583 - val_loss: 0.1393 - val_accuracy: 0.9667\n",
            "Epoch 160/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1389 - accuracy: 0.9500 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
            "Epoch 161/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9333 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
            "Epoch 162/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1354 - accuracy: 0.9500 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
            "Epoch 163/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1372 - accuracy: 0.9417 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
            "Epoch 164/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1325 - accuracy: 0.9500 - val_loss: 0.0989 - val_accuracy: 1.0000\n",
            "Epoch 165/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9500 - val_loss: 0.1098 - val_accuracy: 1.0000\n",
            "Epoch 166/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
            "Epoch 167/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9417 - val_loss: 0.1029 - val_accuracy: 1.0000\n",
            "Epoch 168/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9500 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
            "Epoch 169/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9583 - val_loss: 0.1057 - val_accuracy: 1.0000\n",
            "Epoch 170/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9667 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
            "Epoch 171/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.9417 - val_loss: 0.0959 - val_accuracy: 1.0000\n",
            "Epoch 172/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.9583 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
            "Epoch 173/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9333 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
            "Epoch 174/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1284 - accuracy: 0.9500 - val_loss: 0.1030 - val_accuracy: 1.0000\n",
            "Epoch 175/1000000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
            "Epoch 176/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1303 - accuracy: 0.9583 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
            "Epoch 177/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.0960 - val_accuracy: 1.0000\n",
            "Epoch 178/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9583 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
            "Epoch 179/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.9500 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
            "Epoch 180/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9500 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
            "Epoch 181/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1267 - accuracy: 0.9500 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
            "Epoch 182/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9583 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
            "Epoch 183/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1240 - accuracy: 0.9500 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
            "Epoch 184/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9500 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
            "Epoch 185/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9667 - val_loss: 0.1109 - val_accuracy: 1.0000\n",
            "Epoch 186/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9500 - val_loss: 0.0949 - val_accuracy: 1.0000\n",
            "Epoch 187/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9583 - val_loss: 0.1127 - val_accuracy: 0.9667\n",
            "Epoch 188/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9500 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
            "Epoch 189/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9500 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
            "Epoch 190/1000000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9667 - val_loss: 0.1106 - val_accuracy: 0.9667\n",
            "Epoch 191/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.9417 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
            "Epoch 192/1000000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9667 - val_loss: 0.1062 - val_accuracy: 1.0000\n",
            "Epoch 193/1000000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9583 - val_loss: 0.1018 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTgedaLnrXad"
      },
      "source": [
        "## Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSKqQ_2AraGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "97646506-2cc2-463f-96f6-3c1b2372ade9"
      },
      "source": [
        "# learning curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"r\" is for \"solid red line\"\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"r\" is for \"solid red line\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Py33oAOaQqoI",
        "outputId": "3fe8c1db-f26a-497d-d79f-43c3884b01c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e9LEggQIJTQwdCLlAChKIKgroIioKLC+lMRsaCuhbWwa4HVteIqspYVG+qqoKuiIioWkCZKQDooCEGDCCGUBGkJeX9/nBsYYspAMrlD8n6eZ565c26Zd+7AvDnn3HuOqCrGGGNMMMr5HYAxxpgThyUNY4wxQbOkYYwxJmiWNIwxxgTNkoYxxpigWdIwxhgTNEsapkSIyCcicmVxb+snEUkWkbNCcFwVkebe8n9E5N5gtj2O97lMRGYeb5wFHLePiKQU93FNeIj0OwATvkRkT8DLSsAB4JD3+jpVfSPYY6lq/1BsW9qp6vXFcRwRiQc2AlGqmuUd+w0g6O/QGLCkYQqgqjE5yyKSDIxU1S9ybycikTk/RMaY0s2ap8wxy2l+EJG7ROQ34BURqS4i00UkVUR2essNA/aZLSIjveXhIjJPRB73tt0oIv2Pc9smIjJHRDJE5AsReUZE/ptP3MHE+ICIzPeON1NEagWsv1xENolImojcXcD56S4iv4lIREDZBSKy3FvuJiLfiMguEdkiIk+LSPl8jjVZRP4Z8PoOb59fRWRErm3PE5HvRSRdRH4RkXEBq+d4z7tEZI+InJJzbgP2P1VEFonIbu/51GDPTUFEpI23/y4RWSUiAwPWnSsiq71jbhaR273yWt73s0tEdojIXBGx36swYF+COV51gRrAScC1uH9Lr3ivGwP7gKcL2L878ANQC3gMeElE5Di2fRP4DqgJjAMuL+A9g4nxz8BVQG2gPJDzI9YWeM47fn3v/RqSB1X9FvgdOCPXcd/0lg8Bt3mf5xTgTOCGAuLGi6GfF8+fgBZA7v6U34ErgFjgPGCUiAz21vX2nmNVNUZVv8l17BrAx8BE77M9AXwsIjVzfYY/nJtCYo4CPgJmevv9BXhDRFp5m7yEa+qsArQDvvLK/wqkAHFAHeDvgI15FAYsaZjjlQ2MVdUDqrpPVdNU9V1V3auqGcCDwOkF7L9JVV9Q1UPAq0A93I9D0NuKSGOgK3Cfqh5U1XnAh/m9YZAxvqKqP6rqPuBtIMErHwJMV9U5qnoAuNc7B/l5CxgGICJVgHO9MlR1saouVNUsVU0Gns8jjrxc4sW3UlV/xyXJwM83W1VXqGq2qi733i+Y44JLMutU9XUvrreAtcD5Advkd24K0gOIAR7xvqOvgOl45wbIBNqKSFVV3amqSwLK6wEnqWqmqs5VGygvLFjSMMcrVVX357wQkUoi8rzXfJOOaw6JDWyiyeW3nAVV3estxhzjtvWBHQFlAL/kF3CQMf4WsLw3IKb6gcf2frTT8nsvXK3iQhGpAFwILFHVTV4cLb2ml9+8OB7C1ToKc1QMwKZcn6+7iMzymt92A9cHedycY2/KVbYJaBDwOr9zU2jMqhqYYAOPexEuoW4Ska9F5BSvfDywHpgpIhtEZExwH8OEmiUNc7xy/9X3V6AV0F1Vq3KkOSS/JqfisAWoISKVAsoaFbB9UWLcEnhs7z1r5rexqq7G/Tj25+imKXDNXGuBFl4cfz+eGHBNbIHexNW0GqlqNeA/Acct7K/0X3HNdoEaA5uDiKuw4zbK1R9x+LiqukhVB+GarqbhajCoaoaq/lVVmwIDgdEicmYRYzHFwJKGKS5VcH0Eu7z28bGhfkPvL/ckYJyIlPf+Sj2/gF2KEuP/gAEicprXaX0/hf//eRO4BZec3skVRzqwR0RaA6OCjOFtYLiItPWSVu74q+BqXvtFpBsuWeVIxTWnNc3n2DOAliLyZxGJFJFLgba4pqSi+BZXK7lTRKJEpA/uO5rifWeXiUg1Vc3EnZNsABEZICLNvb6r3bh+oIKaA00JsaRhissEoCKwHVgIfFpC73sZrjM5DfgnMBV3P0lejjtGVV0F3IhLBFuAnbiO2oLk9Cl8parbA8pvx/2gZwAveDEHE8Mn3mf4Ctd081WuTW4A7heRDOA+vL/avX334vpw5ntXJPXIdew0YACuNpYG3AkMyBX3MVPVg7gk0R933p8FrlDVtd4mlwPJXjPd9bjvE1xH/xfAHuAb4FlVnVWUWEzxEOtbMqWJiEwF1qpqyGs6xpRFVtMwJzQR6SoizUSknHdJ6iBc27gxJgTsjnBzoqsLvIfrlE4BRqnq9/6GZEzpZc1TxhhjgmbNU8YYY4JWqpqnatWqpfHx8X6HYYwxJ4zFixdvV9W4YLcvVUkjPj6epKQkv8MwxpgThojkHgmgQNY8ZYwxJmiWNIwxxgTNkoYxxpighaxPQ0QaAa/hhrtWYJKqPpVrGwGewo1yuRcYnjM0srg5ou/xNv2nqr4aqliNMccnMzOTlJQU9u/fX/jGxlfR0dE0bNiQqKioIh0nlB3hWcBfVXWJN5/AYhH53Bv9M0d/3BgzLXAT7TwHdA8YTC4Rl3AWi8iHqrozhPEaY45RSkoKVapUIT4+nvzn0DJ+U1XS0tJISUmhSZMmRTpWyJqnVHVLTq3Bm/BmDUePzQ9uyIfX1FmIm9ugHnAO8Lmq7vASxedAv1DFaow5Pvv376dmzZqWMMKciFCzZs1iqRGWSJ+GiMQDnXDDJAdqwNGTyqR4ZfmV53Xsa0UkSUSSUlNTiytkY0yQLGGcGIrrewp50hCRGOBd4FZVTS/u46vqJFVNVNXEuLig70852gMPwGefFW9gxhhTCoU0aXiTyr8LvKGq7+WxyWaOnomsoVeWX3lojB9vScOYE1BaWhoJCQkkJCRQt25dGjRocPj1wYMHC9w3KSmJm2++udD3OPXUU4sl1tmzZzNgwIBiOZafQnn1lAAvAWtU9Yl8NvsQuElEpuA6wner6hYR+Qx4SESqe9udDfwtVLFStSqkF3slyBgTYjVr1mTp0qUAjBs3jpiYGG6//fbD67OysoiMzPtnLjExkcTExELfY8GCBcUTbCkRyppGT9ysXGeIyFLvca6IXC8i13vbzAA24GYhewE38xiqugN4AFjkPe73ykLDkoYxpcbw4cO5/vrr6d69O3feeSffffcdp5xyCp06deLUU0/lhx9+AI7+y3/cuHGMGDGCPn360LRpUyZOnHj4eDExMYe379OnD0OGDKF169Zcdtll5IwSPmPGDFq3bk2XLl24+eabC61R7Nixg8GDB9OhQwd69OjB8uXLAfj6668P15Q6depERkYGW7ZsoXfv3iQkJNCuXTvmzp1b7OfsWISspqGq8zgyqX1+2yhuCs281r0MvByC0P7IkoYxRXfrreD91V9sEhJgwoRj3i0lJYUFCxYQERFBeno6c+fOJTIyki+++IK///3vvPvuu3/YZ+3atcyaNYuMjAxatWrFqFGj/nBPw/fff8+qVauoX78+PXv2ZP78+SQmJnLdddcxZ84cmjRpwrBhwwqNb+zYsXTq1Ilp06bx1VdfccUVV7B06VIef/xxnnnmGXr27MmePXuIjo5m0qRJnHPOOdx9990cOnSIvXv3HvP5KE6lasDC41aliiUNY0qRiy++mIiICAB2797NlVdeybp16xARMjMz89znvPPOo0KFClSoUIHatWuzdetWGjZseNQ23bp1O1yWkJBAcnIyMTExNG3a9PD9D8OGDWPSpEkFxjdv3rzDieuMM84gLS2N9PR0evbsyejRo7nsssu48MILadiwIV27dmXEiBFkZmYyePBgEhISinRuisqSBriaxpYtfkdhzIntOGoEoVK5cuXDy/feey99+/bl/fffJzk5mT59+uS5T4UKFQ4vR0REkJWVdVzbFMWYMWM477zzmDFjBj179uSzzz6jd+/ezJkzh48//pjhw4czevRorrjiimJ932NhY0+BNU8ZU4rt3r2bBg3cbV6TJ08u9uO3atWKDRs2kJycDMDUqVML3adXr1688cYbgOsrqVWrFlWrVuWnn36iffv23HXXXXTt2pW1a9eyadMm6tSpwzXXXMPIkSNZsmRJsX+GY2FJAyxpGFOK3Xnnnfztb3+jU6dOxV4zAKhYsSLPPvss/fr1o0uXLlSpUoVq1aoVuM+4ceNYvHgxHTp0YMyYMbz6qhtab8KECbRr144OHToQFRVF//79mT17Nh07dqRTp05MnTqVW265pdg/w7EoVXOEJyYm6nFNwnTvvfDQQ5CVBXZ3qzFBW7NmDW3atPE7DN/t2bOHmJgYVJUbb7yRFi1acNttt/kd1h/k9X2JyGJVLfzaY4/VNMDVNLKzweerEowxJ6YXXniBhIQETj75ZHbv3s11113nd0ghYx3h4JIGuCaqgA40Y4wJxm233RaWNYtQsJoGHJ00jDHG5MuSBljSMMaYIFnSAEsaxhgTJEsa4O4IB0saxhhTiDKfNFTh2keaMpVLLGkYc4Lp27cvn+Wa1mDChAmMGjUq33369OlDzqX55557Lrt27frDNuPGjePxxx8v8L2nTZvG6tVHZq++7777+OKLL44l/DyF+xDqZT5piMDbn8SwgFMtaRhzghk2bBhTpkw5qmzKlClBDRoIbnTa2NjY43rv3Enj/vvv56yzzjquY51IynzSAIiNFXYRa0nDmBPMkCFD+Pjjjw9PuJScnMyvv/5Kr169GDVqFImJiZx88smMHTs2z/3j4+PZvn07AA8++CAtW7bktNNOOzx8Orh7MLp27UrHjh256KKL2Lt3LwsWLODDDz/kjjvuICEhgZ9++onhw4fzv//9D4Avv/ySTp060b59e0aMGMGBAwcOv9/YsWPp3Lkz7du3Z+3atQV+vnAcQt3u0wBiqwu7UmpA+urCNzbG5MmPkdFr1KhBt27d+OSTTxg0aBBTpkzhkksuQUR48MEHqVGjBocOHeLMM89k+fLldOjQIc/jLF68mClTprB06VKysrLo3LkzXbp0AeDCCy/kmmuuAeCee+7hpZde4i9/+QsDBw5kwIABDBky5Khj7d+/n+HDh/Pll1/SsmVLrrjiCp577jluvfVWAGrVqsWSJUt49tlnefzxx3nxxRfz/XzhOIS61TSAatVgV0RNyMjwOxRjzDEKbKIKbJp6++236dy5M506dWLVqlVHNSXlNnfuXC644AIqVapE1apVGThw4OF1K1eupFevXrRv35433niDVatWFRjPDz/8QJMmTWjZsiUAV155JXPmzDm8/sILLwSgS5cuhwc5zM+8efO4/PLLgbyHUJ84cSK7du0iMjKSrl278sorrzBu3DhWrFhBlZwLfIqZ1TSA2FhIlurWPGVMEfg1MvqgQYO47bbbWLJkCXv37qVLly5s3LiRxx9/nEWLFlG9enWGDx/O/v37j+v4w4cPZ9q0aXTs2JHJkycze/bsIsWbM7x6UYZW93MI9ZDVNETkZRHZJiIr81l/R8A0sCtF5JCI1PDWJYvICm/dcYxAeGxiY2GXWp+GMSeimJgY+vbty4gRIw7XMtLT06lcuTLVqlVj69atfPLJJwUeo3fv3kybNo19+/aRkZHBRx99dHhdRkYG9erVIzMz8/Bw5gBVqlQhI4/WiVatWpGcnMz69esBeP311zn99NOP67OF4xDqoaxpTAaeBl7La6WqjgfGA4jI+cBtueYB76uq20MY32GxsbAr22bvM+ZENWzYMC644ILDzVQ5Q4m3bt2aRo0a0bNnzwL379y5M5deeikdO3akdu3adO3a9fC6Bx54gO7duxMXF0f37t0PJ4qhQ4dyzTXXMHHixMMd4ADR0dG88sorXHzxxWRlZdG1a1euv/764/pcOXOXd+jQgUqVKh01hPqsWbMoV64cJ598Mv3792fKlCmMHz+eqKgoYmJieO21PH96iyykQ6OLSDwwXVXbFbLdm8AsVX3Be50MJB5r0jjeodHHjoX774eshEQivg95xcaYUsOGRj+xlIqh0UWkEtAPCJzpXYGZIrJYRK4tZP9rRSRJRJJSU1OPK4acy7TTd2Uf1/7GGFNW+J40gPOB+bmapk5T1c5Af+BGEemd386qOklVE1U1MS4u7rgCyEkau9NtAiZjjClIOCSNocBbgQWqutl73ga8D3QLZQA5SWNXRkQo38aYUqk0zf5ZmhXX9+Rr0hCRasDpwAcBZZVFpErOMnA2kOcVWMXlcNLIrATenZvGmMJFR0eTlpZmiSPMqSppaWlER0cX+Vghu3pKRN4C+gC1RCQFGAtEAajqf7zNLgBmqurvAbvWAd4XN1d3JPCmqn4aqjghIGkQ627w866jNsYUrGHDhqSkpHC8/Ymm5ERHR9OwYcMiHydkSUNVCx0xTFUn4y7NDSzbAHQMTVR5Oypp7NwJtWqV5Nsbc8KKioqiSZMmfodhSlA49Gn47qik8dtv/gZjjDFhzJIGRybu20UsbNnibzDGGBPGLGkAERFQtUq2JQ1jjCmEJQ1PbHVhl9SwpGGMMQWwpOGJjRV2RdexpGGMMQWwpOGJjYVdkXHw669+h2KMMWHLkoYnNhZ2SXWraRhjTAEsaXjcnBpVLWkYY0wBLGl4YmNhd2Yl2LHDhhIxxph8WNLwVKsGuw9Ek43YDX7GGJMPSxqe2FhQFTKoYk1UxhiTD0sanpyhRHZg92oYY0x+LGl4atd2z9uobZfdGmNMPixpeOrUcc/bpK7VNIwxJh+WNDw5SWNr1RaWNIwxJh+WNDw5zVNbKzWx5iljjMmHJQ1PdLS77HZrxXjYtMnvcIwxJiyFLGmIyMsisk1E8pzfW0T6iMhuEVnqPe4LWNdPRH4QkfUiMiZUMeZWpw5sjWwAyclgcx4bY8wfhLKmMRnoV8g2c1U1wXvcDyAiEcAzQH+gLTBMRNqGMM7D6tSBrdm1YN8+2Lq1JN7SGGNOKCFLGqo6B9hxHLt2A9ar6gZVPQhMAQYVa3D5qFMHtu6v5l4kJ5fEWxpjzAnF7z6NU0RkmYh8IiIne2UNgF8CtknxyvIkIteKSJKIJKWmphYpmDp1YGt6Rfdi48YiHcsYY0ojP5PGEuAkVe0I/BuYdjwHUdVJqpqoqolxcXFFCqhOHdiZHslBoixpGGNMHnxLGqqarqp7vOUZQJSI1AI2A40CNm3olYXc4Rv8arSx5iljjMmDb0lDROqKiHjL3bxY0oBFQAsRaSIi5YGhwIclEdPhG/zqJVhNwxhj8hAZqgOLyFtAH6CWiKQAY4EoAFX9DzAEGCUiWcA+YKiqKpAlIjcBnwERwMuquipUcQY6nDRqtIaN80viLY0x5oQSsqShqsMKWf808HQ+62YAM0IRV0EO3xUe0xx+/hkOHYKIiJIOwxhjwpbfV0+FlcM1jQqNITPThhMxxphcLGkEqFzZPbaKlz2sX8MYY45iSSOXOnVga2ZN92L9en+DMcaYMGNJI5d69eDX9BgoXx7WrvU7HGOMCSuWNHKJj4fkTQLNm8MPP/gdjjHGhBVLGrnEx0NKCmS1aGNJwxhjcrGkkUuTJu5K25T63eCnn9xVVMYYYwBLGn8QH++eN1btCFlZsGGDr/EYY0w4saSRS07SSI5s7hasicoYYw6zpJFLo0YgAskH67sCSxrGGHOYJY1cypeHhg0heWtFN66IJQ1jjDnMkkYe4uO9m8FbtbKkYYwxASxp5CE+3ptOo3VrWLMGVH2OyBhjwoMljTzEx8PmzXCwdQdIS4Nt2/wOyRhjwoIljTzEx0N2NqTU7uwKVq70NR5jjAkXljTy0KSJe94Y3cYtWNIwxhjAkkaemufcorGtOtSqZUnDGGM8IUsaIvKyiGwTkTx/cUXkMhFZLiIrRGSBiHQMWJfslS8VkaRQxZifhg0hJsYb5LZdO0saxhjjCWVNYzLQr4D1G4HTVbU98AAwKdf6vqqaoKqJIYovXyJHLpw6nDTsCipjjAld0lDVOcCOAtYvUNWd3suFQMNQxXI82rQJSBp79rg5w40xpowLlz6Nq4FPAl4rMFNEFovItQXtKCLXikiSiCSlpqYWW0Bt2rjLbtObeK1m1kRljDH+Jw0R6YtLGncFFJ+mqp2B/sCNItI7v/1VdZKqJqpqYlxcXLHF1ca7cGptxMluwZKGMcb4mzREpAPwIjBIVdNyylV1s/e8DXgf6FbSsbVu7Z7Xbq7iesYtaRhjjH9JQ0QaA+8Bl6vqjwHllUWkSs4ycDZQ4r/YzZpBZGSuznBjjCnjIkN1YBF5C+gD1BKRFGAsEAWgqv8B7gNqAs+KCECWd6VUHeB9rywSeFNVPw1VnPmJioIWLQKSxqxZbkq/iIiSDsUYY8JGyJKGqg4rZP1IYGQe5RuAjn/co+S1aQMrVgAXtIMDB9z0ry1b+h2WMcb4xveO8HDWpQusWwc7GnZwBdZEZYwp4yxpFKBnT/e8YGcbd8efJQ1jTBlnSaMAXbu6zvD5i6OhaVNLGsaYMs+SRgEqVYLOnWH+fOwKKmOMwZJGoXr2hEWL4GCbjvDjj7B/v98hGWOMbyxpFKJnT5cnlsT0dpfcrlrld0jGGOMbSxqFyOkMn7/Huwp4yRL/gjHGGJ9Z0ihE3brQuDEkJdeEatUsaRhjyjRLGkFITISkJIFOneD77/0OxxhjfBNU0vDGgyrnLbcUkYEiEhXa0MJHYiKsXw872/aEZcsgK8vvkIwxxhfB1jTmANEi0gCYCVyOm5mvTEj05g5cUrWP6xVfu9bXeIwxxi/BJg1R1b3AhcCzqnoxcHLowgovXbq456SD3nAi1q9hjCmjgk4aInIKcBnwsVdWZoZ7rVHD3RCetCnO3fG3eLHfIRljjC+CTRq3An8D3lfVVSLSFJgVurDCT9eukLRY3ML8+X6HY4wxvggqaajq16o6UFUf9TrEt6vqzSGOLax06QLJyZDWrb+7gmrXLr9DMsaYEhfs1VNvikhVbya9lcBqEbkjtKGFl4QE97ys7jmQnQ3z5vkbkDHG+CDY5qm2qpoODAY+AZrgrqAqMzp6N4QvzTwZKlSA2bN9jccYY/wQbNKI8u7LGAx8qKqZgBa2k4i8LCLbRCTP4WHFmSgi60VkuYh0Dlh3pYis8x5XBhlnyNSuDfXqwbLVUdCjhyUNY0yZFGzSeB5IBioDc0TkJCA9iP0mA/0KWN8faOE9rgWeAxCRGrg5xbsD3YCxIlI9yFhDJiEBli4F+vSxfg1jTJkUbEf4RFVtoKrnqrMJ6BvEfnOAHQVsMgh4zTvmQiBWROoB5wCfq+oOVd0JfE7ByadEdOwIa9bAwdPOcP0aX33ld0jGGFOigu0IryYiT4hIkvf4F67WUVQNgF8CXqd4ZfmV5xXbtTlxpaamFkNI+UtIgMxMWF3tFDd44ccfF76TMcaUIsE2T70MZACXeI904JVQBXUsVHWSqiaqamJcXFxI3yunM3zZ6ig45xyYMcPVOIwxpowINmk0U9WxqrrBe/wDaFoM778ZaBTwuqFXll+5r1q0gIoVvVFEzjsPfvvNRr01xpQpwSaNfSJyWs4LEekJ7CuG9/8QuMK7iqoHsFtVtwCfAWeLSHWvA/xsr8xXERFw+unw7ruQ9af+IALTp/sdljHGlJhgk8b1wDMikiwiycDTwHWF7SQibwHfAK1EJEVErhaR60Xkem+TGcAGYD3wAnADgKruAB4AFnmP+70y3113HWzeDNO/jYPu3S1pGGPKFFEt9HaLIxuLVAVQ1XQRuVVVJ4QssuOQmJioSUlJIX2PrCyIj4d27eDTvo/CmDGwaZOb3s8YY04wIrJYVROD3f6YZu5T1XTvznCA0ccUWSkRGQnXXAOffQYbEi9xhe+/729QxhhTQooy3asUWxQnmJEjXf/G8zObQPv28N57fodkjDEloihJI/h2rVKmQQMYOBBefhkODLwY5s6FrVv9DssYY0KuwKQhIhkikp7HIwOoX0IxhqVRo2D7dng35kpQtSYqY0yZUGDSUNUqqlo1j0cVVY0sqSDD0ZlnQrNm8PSHjaBNG3jrLb9DMsaYkCtK81SZVq4c3HorfPONMOeUu1wT1S+/FL6jMcacwCxpFMHVV0OdOvDPHy52TVRTp/odkjHGhJQljSKoWBFGj4bP51diUZsr4M03/Q7JGGNCypJGEY0aBdWrw4OR97lxqJYt8zskY4wJGUsaRVSlCtx8M3ywohkrojrDCy/4HZIxxoSMJY1icPPNEBMDD9f/N/z3v7B3r98hGWNMSFjSKAY1asANN8DUX05h3e44eOcdv0MyxpiQsKRRTEaPhvLl4ZGqD1sTlTGm1LKkUUzq1IGRI4XX9lzAz/N/hlWr/A7JGGOKnSWNYnTHHUC5cowvdxe8+KLf4RhjTLGzpFGMGjeGK68UXpRr2PrKDNhXHJMbGmNM+LCkUczGjIGDGsUTu0e4K6mMMaYUCWnSEJF+IvKDiKwXkTF5rH9SRJZ6jx9FZFfAukMB6z4MZZzFqXlzuPRSeLbcTex87AXIzvY7JGOMKTYhSxoiEgE8A/QH2gLDRKRt4DaqepuqJqhqAvBvIHA2o30561R1YKjiDIXbbxf2ZFfmrfWJ8NFHfodjjDHFJpQ1jW7AelXdoKoHgSnAoAK2HwaUivHFO3WCDu2VV8pfB4884gYzNMaYUiCUSaMBEDhWeIpX9gcichLQBPgqoDhaRJJEZKGIDM7vTUTkWm+7pNTU1OKIu8hE4KoRQtLBjqxcmOEmFDfGmFIgXDrChwL/U9VDAWUnqWoi8Gdggog0y2tHVZ2kqomqmhgXF1cSsQblsssgMlJ5ueqtcN99VtswxpQKoUwam4FGAa8bemV5GUqupilV3ew9bwBmA52KP8TQiYuDSy4R/rN/OD8v+g2mTfM7JGOMKbJQJo1FQAsRaSIi5XGJ4Q9XQYlIa6A68E1AWXURqeAt1wJ6AqtDGGtIPPQQEBHB7VUnwe23w/79fodkjDFFErKkoapZwE3AZ8Aa4G1VXSUi94tI4NVQQ4Epqke137QBkkRkGTALeERVT7ikcdJJMGaM8E56P2ZtaAxPPOF3SMYYUySipaitPTExUZOSkvwO4yj79kHbthCzYxPfH2xH5LLF0LKl32EZYwwAIrLY6y0A++YAAB3JSURBVD8OSrh0hJdaFSvCk0/CyvST+JfcTub/XQVZWX6HZYwxx8WSRgkYNAjOPhvG7BtL1UVf8NaQd/0OyRhjjosljRIgAu+9B2++CW1rbuOWD/qS8bJN1GSMOfFY0ighlSvDsGHw3Af1SaU2j127HlafcH37xpgyzpJGCevWM4pLB+3nX4duYfmQ+yEz0++QjDEmaJY0fPDEs9FUryEMWPMYL184nTFjIC3N76iMMaZwljR8UL8+TP+iIjsia3P19At49FG46CI4eNDvyIwxpmCWNHzSqRMkLS7H4g5X8WrUSL7+GgYPdh3mhw4Vvr8xxvjBkoaPWncoT+fPH+WKZvMZH/V3vpmbyUUXudn/jDEmHFnS8Fvt2jB7Nre3+oht2XFcNSCVJ5+E77/3OzBjjPkjSxrhoE4d+PxzourW5F/ze1Az5gBXX62kp/sdmDHGHM2SRrioWxdmzqR6tWwm7b6EFd9n0fvUTDbnN5i8Mcb4wJJGOGnWDH78kUFvDePj8hfy05qDdO6szJrld2DGGONY0gg3UVEwdChnv3El32Z3pcbvv3DWWcqnn/odmDHGWNIIX0OG0PbFv/LdwU60i1jLsEuyWLfO76CMMWWdJY1wdvXVVJn/KdNqjSQiYxdtWmdzyilu/vHHHoO9e/0O0BhT1ljSCHddu9Jk+QfMO/Uu7sp+mKiNP/LNgmzuugvatIGZM/0O0BhTloQ0aYhIPxH5QUTWi8gfblkTkeEikioiS73HyIB1V4rIOu9xZSjjDHu1atF6ziQevGc/c7a2YoM05+vHFxETA/36wf33QymagNEYE8ZCljREJAJ4BugPtAWGiUjbPDadqqoJ3uNFb98awFigO9ANGCsi1UMV6wkhIgIeeABmz4by5el9eze+6z+Wy4ZlM3YsPPig3wEaY8qCUNY0ugHrVXWDqh4EpgCDgtz3HOBzVd2hqjuBz4F+IYrzxHL66bB0KVx7LZX/dT+vrTuFywfu4t574fnn/Q7OGFPaRYbw2A2AXwJep+BqDrldJCK9gR+B21T1l3z2bZDXm4jItcC1AI0bNy6GsE8A0dEuQ5xxBnLjjby4tCHbWizj+uubsXAhNGkCJ50EV1zhZg00xpji4ndH+EdAvKp2wNUmXj3WA6jqJFVNVNXEuLi4Yg8wrF16KaxeTfkLzmP6ulbcWfMlJk+GsWNh+HC4+GLYvdttmp1t/R7GmKILZdLYDDQKeN3QKztMVdNU9YD38kWgS7D7Gk/t2jB1KpHT3uXR2IfZSSz7/3Q+4/+6hWnToG1buPVWt9mAAfD7734HbIw5kYUyaSwCWohIExEpDwwFPgzcQETqBbwcCKzxlj8DzhaR6l4H+NlemcnPoEGwejWxT4ylwqJ53P5kQxae/yC1a2Ty1FPQvj18+imccQasWVP44YwxJi8hSxqqmgXchPuxXwO8raqrROR+ERnobXaziKwSkWXAzcBwb98dwAO4xLMIuN8rMwUpXx5uuw3Wr4e//IXE6eNI2lSbtLETmfXaL7z3HqxdC+3awc03w759fgdsjDnRiJaihu7ExERNSkryO4zw8cMPcMst8JlXSevfn9S7JzDuzZY8+6y7ObB5c5drhg6FJUvg22/hjTfcoLvGmNJPRBaramKw2/vdEW5CqVUr1ya1Zo27x2PBAuJOb8sz2y/lkyfWUK6csmkTLFjgOs0ffRTmzoWrroIZM6BLF/jkkyOHy86GlBT/Po4xxn9W0yhLUlPdoFUvvgi7dkFiIpx1Flmn9ubriv1o0lT45BO46Sa3eVSUu2T3nXdg4EC47jp45RWXg5o18/ejGGOKh9U0TP7i4mD8ePjlF3jmGTh0CB5/nMiB53LmUwNpenAtN9wA11wDI0dCcjIkJMBFF8Hf/gaTJkFmJkyY4A6XnQ133gm3337025Siv0OMMblYTaOsO3jQJZC773Y94927w5VXwrBhEBvL7t3Qvz98842rXXTpAtOnw4YN8I9/wHPPucMsWQKdOsG2bdCnj0s6o0f7+smMMUE41pqGJQ3jbN3qesAnT4YVK6ByZXeHYIcOZDRL4O4PunHFFa7TvGNHiIyErCz4y1/g9dfdpbxTp8LZZ8OsWdCwoaupRET4/LmMMQU61qQRymFEzImkTh1XNbjtNldteOqpw+1RVYCJvXrBxQ9CYi/GjHE1iiFD3Ci71au7kXZbt4affoILL4T33nNjKyYmQrlyUKVK3m/7889uXfWyPRylMScMq2mY/B044GogH3wAjzwCv/4KPXq4TvSOHeG++6BtW3budHeb16oFgwe7y3fr1nUJY80a1w/yxBOu8nLokKuNVKvmyk86CapWhcWL3XpjTMmy5ilLGqGxdy88/jh8/LHLCF99BXv2QN++rmrRoYO77dyrMlxzjbtIq25daNDAJYUcUVHw0ksuWQwe7MpGjoQXXvDhcxlTxlnSsKRRMrZvd73gkye7XvEcLVvCbbextu2F3PNUHI88KsTHu/sLa9d2tYvRo2HdOpdn1q6Fyy93F3XdeKN7rljRrw9lTNljScOSRslShc2bXef5ihXw7rvw3XduXZUq7k7Bc86BChWgWzeoUoXly92VVjmX7D74INx1l2vCatrUlV19tetEv+kmN4XIJZe4pi2wznVjipMlDUsa/lJ11+cuWwbz5sHbb7vLrMBdenXWWTB4MKPmXcbzr1di9WrXgQ7w5Zfw97+7nHPHHdC7N5x/vmvGWrHCXQX8449unpD77nP9IsaYorGkYUkjvGzdChs3QkaGG9Lk/fdh40b2E82KDpfR9fLW7g7CypWhcmW08UmM/Gs1Xn0V4uPdrSPbtrkEkZbmOtG//NIllE8/dXlo82aYP98NhWKTThlzbCxpWNIIb6qu2jBtmksgS5cevT46mrQLRtL648fZnl6Bl19SVq4SnngC7rnHDaH13/+6fpBzznE3Eo4fDzt2uEMOCnZCYWMMYEnDksaJ5uefYdMmNzvUnj2uGvH668z4vTdTuZSX6t1LVquT+bLCufQbUZ+IxE4QFcUTbzfkH/cL6enuLvXdu12tY+lS1y/fsuWRWkdamhstvntekw0bU8ZZ0rCkceI7cMD1iXz7revgWL/eXWa1a9eRbWrXJnvAQDZfdif1erdg2jTXPFWvHmzZAv/8p+sfee01+OtfXeKYPNmNkGKMOcKShiWN0ikry3VcJCe7jo45c9xNh3v3QuvWaMcEzlrxJGmZVahbI5PPvo2lSxd3f8ipp7p7Q+bNc+Nm9esHq1e7RHLaadYPYso2SxqWNMqO7dvdHYHffQcLF8JvvwGwnwr8qcIcVtCeRy5fzbX31WVPtQb06uU6zT/6yN3BvmOHa9p64gnXsW5MWRRWSUNE+gFPARHAi6r6SK71o4GRQBaQCoxQ1U3eukPACm/Tn1V1IIWwpFGGZWfDokUukWRkcPC5lzg491tiNMOtb9GCH5r2p/Osx9mXGUnVqnDvvcLTT7vKyy23wJNPHql1bN3qBmWsWdO3T2RMiQibpCEiEcCPwJ+AFNxc38NUdXXANn2Bb1V1r4iMAvqo6qXeuj2qGnMs72lJwxxl3z7XDjV7tmubWraMVzaezg08yztyKQNar+f3MwdyR/KNPDe9Ef/+t7uZcPNmVwM5eNDd9H7ppX5/EGNCJ5ySxinAOFU9x3v9NwBVfTif7TsBT6tqT++1JQ1T/NatY/9nXxO9dZNr1vr6a/TAAQbyITM5m/E1H+WtzItYsb8FrZtmsnhtZZ57JpvrbyiHav79H9nZbmrcvn2hUqWS/UjGFEU4zdzXAPgl4HWKV5afq4GAGamJFpEkEVkoIoPz20lErvW2S0pNTS1axKb0a9GC6JtGuhs+PvsM0tKQ6dOZPOYHmlbfyS1p97Ew/WReOXgZ36yNpT8zuPnGLEZ3/JIaFffyxFUrIDOTtQt2MPrmLHr0cDMZDhni+kluvjm4MBYscFcZG3PCUdWQPIAhuH6MnNeX42oSeW37f8BCoEJAWQPvuSmQDDQr7D27dOmixhyv7GzV5GTVn35S1ZUrVadP1x3PvqVNK25WUK0vmzWKA/qE3KYV+V2jOKDtKq5XUC1XLltP7XpQQXXevILf59NPVUF1+HD3+s03Vb/4IuQfz5g8AUl6DL/tvjdPichZwL+B01V1Wz7HmgxMV9X/FfSe1jxlQiElxT1aNMmifZsstuyMpmP9VD4Z/Dz1vp3G/MUVEJQOLKdtubXEVDzE1wOfYMe+irzzU2duPn8jVc/uAaedxu49EbRr544XFeVuij//fDcI4wcfwLnn+v1pTVkTTn0akbiO8DOBzbiO8D+r6qqAbToB/wP6qeq6gPLqwF5VPSAitYBvgEEa0ImeF0saJtTmzXNzgfzrX1Cjhlf444/w/fewZQtfzjjAgC9uoW65baRm1+R3rUwbVnMLT7E0ugczss4mJasub1z+GZe90Z+IckpsNaXRSeVYvVpISoKTT/b1I5oyJmyShhfMucAE3CW3L6vqgyJyP6469KGIfAG0B7Z4u/ysqgNF5FTgeSAb1+8yQVVfKuz9LGmYcLBgAQwc6H78b7gBbhiVzY6d5YiJ3McZdVYxIvJ1Bm2ayCVM5R0u4UWu5vzKs2ixfzln1F/Le0Pf4e2tp/PflQns+L08D586nd6nixtYKzY2z/fMznaDC3/9NfTs6YaTNyYYYZU0SpolDRMu9u93U4iIuNFPtm93c4WUy7n0JDmZjd/8xtvTK3FHj7mUW7uaB6YncN/P13CBTON9HUwjfkZQfuYk/swbjIl4nHady5PV83TWN+pDgwMbqZSxlUX72zP6i/4sXOEuNqxXz428YldxmWBY0rCkYU5QGRkusWzfDqNH7WP8devZl57JPz9ox7+fjeD3fRFUjdjDwUMR7MdNbxjFQTIpTxzbeCjmYWrHHmRQyjOMb/Uit5+9nOy4OixKqUebM+pR9fRObtiVOnUOT8iuCitXQvPmNmNiWWVJw5KGOYF9/rkb+HfEiKPvCdm+Hd55B1atgvLlskiolULK/lqkH6rMyQ13MyDiE6ov+RJ27aLf7LtYtKsFV5R7g08zz2AtbajHrwxlCh9zHnuIoVGlNPpEL2Thgc58/XsitSr+zu39V3HHpT9TLuVnSE0l+9wBaI9TiIgK5ZX5xm+WNCxpmDLu++/dTYaHDimtWylXXX6Il5/dx5J1VTij9RYaR/3K+l+i+WZXa6pG7uXOqs8zJ+1kZnAu/8fr/I2HmS+9GKtj2U80A6t+zfhObxJXeS/Zm36hXKsW0KMHVK7MXq1IWmZVGtXLgpo1yWremsiTGriMF9hGZ8KWJQ1LGsb8QXa2u5mwSpUjZRkZbnytihVBD2by8D2/c/f4Ix3tpzRPpWWFZKas6cgplZdzT+0XGPrLY1xc/kPu2nMPo3iOz/kTWUTxEH+jJT9yJa8yqcLN/LnWTDceS1ycG2a4bl2oXt115Jcrx+Hb6zt1gl69+G3zIWJqViCmmk0AX9IsaVjSMOa4zZvnfuvr1YNevdzv+uuvu3nZAWrXdtPvRkQo0RWUm67cw/oN5Xj3sxhEFFWhSdXt/DDwTlJrn8w/pyfweXJzpsaMpHPG15CZ+Yf3nMKljOBlust3fHXSCCT+JHYdrMS/V/ZlRPtFNOjWAPbt41dpwJStfbnp8t2UrxQJO3e6mbe8qYKpXNklpcaNA644MIU51qQRGcpgjDEnltNO+2PZ5ZfDunVuEOH//tfdhPjOO8KTTwqtW1clKwuuvx527hQuvhiGDavFdVEv878X3JiRsbFwtn7OzG+Uzq33sj1Vmf5pJB99XI5lSZn89FtlGlZLZ/buPnzQ6CbqpP3An38cS/KB+iSveZ+Xvv8/sipV5ZK0/zFfe9LgvUu5lLcBeIw7eIeLeZeLaJwzalFOAtm3D+rXh6pVObAnk3+Xu4Vlh9rxXIsniKlXxY1KWaGCm/Zx2zZITHRXInz7LVStCm3aQK1a7gNUrOiqZtu2uYlYWrXK9/Ln0s5qGsaYYqPqfnuXLIFu3eDNN11Zr15uupPmzd10vNnZ0KgRnHKK2+6GG9x+v/7qfsMbN4bWrd19JykpMHEi3H8/VIzO5vSE3Xzy2Eq2aRxNzmnB3v0RNIrbR+82qfy6NZK2FdYzovkcOjdMhc2bSd+t9Fg4gTV7GgHQv/IcPih3AVEZO4L/YOXKuaADX7duDdHRLjE1b+7a/w4ccOt+/tklmSZNoFkziI931bQKFVxfz9atbkiA005zx0hPd9W6unVdosrMdNMfHzrkHpUqHd22WIysecqShjG+Wr4cPv3UzVFSoYIr27rV1VK+/NL9gX/BBa47I7CP/Isv3JAq117rpuvdtAnat3e/q/PmuSayRo3g4Yfhl1/gqadg/Hh46y0YM8ZN7li/vrvCLCrK1YyaN4d//APGjYP33oPUVLjuOhhxVTYv3vszotkk/VSdcU9WY9yAJBKr/ugmk//9d3en/86d7pGR4fpkateGatVcVly2jOVpDaizfRV1fl7kftQrVHA/8g0butrKxo1uwpasrOBPYJUqLmHk/m1u1gxatICYGDcd8r597vLp/ftd2cKFx/V9WdKwpGHMCevQITcOV44zzoBZs1ySmTLFJZKWLeHMM90d8IMGHanN5CSgDRuga1fXL/P889C/P/zpT/Duu279ffe5QY5vusm1Ok2Y4P6wb9oUvvoKnn7a/RaPGBEwVAyuZWrJElfh6NXL3UDZo4fbLynp8K0vf6CZWSycvp0ZHytdWqQz+Oy9LvlkZJA55xuionCJQpW1SXu4851EHuo3l0OVqzLgxUH8qXUKD/edSZ1181i8sgKPpwzlyV7vUScum6R11Wgcm06dppVd4MfhWJNGyEa59eNho9waU7qsXKn6yCOqBw8eKTvrLNWoKNXTT1fduDHv/T7/XDU62o0mLKK6atWRddnZqldd5dZFRKgOGaI6bZpquXKqkZHu2aUht9yuneo116hWrnykvHFj1SZNVGvVcsc/7zzVLl1UzzhD9fffVfftU/32W9WPPlI99dQj+1WurJqSonrokOrTT7vXY8e6uA4edMcA1bp1VRs2VK1Rw33W6tVVX3tNtX59t75XL9Ubbzxy3O7dVTMzj+8cEy6j3PrBahrGlH4HD7oaSWF3sKemwosvuv7qUaOOXpeV5VpzOnRwrUgAjz3mbqB8/nlX2/n4Y9dKNXu2q9VcfLHre9mzB0aPhp9+cus+/hgeeQROOsl1ZfTt61qkNmxwx61TxzWRde3qrj4++2zXsvTFF64LY+tW15w3c6YbCPOhh9y89fv2uWa56Gg3e+Ty5a42c/vt7ngAN97oalS//grPPHN859NqGsYYU8xy/xW/b5/qhg1uOStLde5ct83Eie4v/xYtVN96S3XWLNWMjCP73XPPkRrH88+rpqerNmt2pMZwxRVuu02bVFevPrLf77+r3nWX6syZ7vWECapPPulqTUWF1TSspmGM8c+SJdC2rash5LZvn7sS7OKLXV8IwNKlMGmSq0307l3yN9BbR7glDWOMCVo4zRFujDGmlLGkYYwxJmiWNIwxxgQtpElDRPqJyA8isl5ExuSxvoKITPXWfysi8QHr/uaV/yAi54QyTmOMMcEJWdIQkQjgGaA/0BYYJiJtc212NbBTVZsDTwKPevu2BYYCJwP9gGe94xljjPFRKGsa3YD1qrpBVQ8CU4BBubYZBLzqLf8POFNExCufoqoHVHUjsN47njHGGB+FMmk0gJyxigFI8cry3EZVs4DdQM0g9zXGGFPCTviOcBG5VkSSRCQpNTXV73CMMaZUC+UkTJuBRgGvG3pleW2TIiKRQDUgLch9AVDVScAkABFJFZFNxxhnLWD7Me5TksI5vnCODSy+ogjn2MDiK4rcsZ10LDuHMmksAlqISBPcD/5Q4M+5tvkQuBL4BhgCfKWqKiIfAm+KyBNAfaAF8F1hb6iqcccapIgkHcvdkCUtnOML59jA4iuKcI4NLL6iKGpsIUsaqpolIjcBnwERwMuqukpE7scNkPUh8BLwuoisB3bgEgvedm8Dq4Es4EZVPRSqWI0xxgQnpHOEq+oMYEausvsClvcDF+ez74PAg6GMzxhjzLE54TvCi8EkvwMoRDjHF86xgcVXFOEcG1h8RVGk2ErVKLfGGGNCy2oaxhhjgmZJwxhjTNDKdNIobEDFEo6lkYjMEpHVIrJKRG7xyseJyGYRWeo9zvUxxmQRWeHFkeSV1RCRz0Vknfdc3afYWgWco6Uiki4it/p1/kTkZRHZJiIrA8ryPFfiTPT+HS4Xkc4+xTdeRNZ6MbwvIrFeebyI7As4h//xKb58v8uSHOA0n9imBsSVLCJLvXI/zl1+vyXF8+/vWOaGLU0P3GXAPwFNgfLAMqCtj/HUAzp7y1WAH3EDPY4Dbvf7fHlxJQO1cpU9BozxlscAj4ZBnBHAb7iblnw5f0BvoDOwsrBzBZwLfAII0AP41qf4zgYiveVHA+KLD9zOx/OX53fp/T9ZBlQAmnj/ryNKMrZc6/8F3Ofjucvvt6RY/v2V5ZpGMAMqlhhV3aKqS7zlDGANJ8Z4W4GDTr4KDPYxlhxnAj+p6rGODlBsVHUO7t6jQPmdq0HAa+osBGJFpF5Jx6eqM9WNAQewEDcSgy/yOX/5KdEBTguKTUQEuAR4K1TvX5gCfkuK5d9fWU4aYTsoorh5RToB33pFN3nVxpf9av7xKDBTRBaLyLVeWR1V3eIt/wbU8Se0owzl6P+04XL+8jtX4fhvcQTur88cTUTkexH5WkR6+RUUeX+X4XT+egFbVXVdQJlv5y7Xb0mx/Psry0kjLIlIDPAucKuqpgPPAc2ABGALrurrl9NUtTNujpQbRaR34Ep1dV1fr+EWkfLAQOAdryiczt9h4XCu8iMid+NGYnjDK9oCNFbVTsBo3BA/VX0ILSy/y1yGcfQfLL6duzx+Sw4ryr+/spw0gh4UsaSISBTuS35DVd8DUNWtqnpIVbOBF/BxXhFV3ew9bwPe92LZmlOV9Z63+RWfpz+wRFW3QnidP/I/V2Hzb1FEhgMDgMu8Hxa8Zp80b3kxrs+gZUnHVsB3GRbnT9ygqxcCU3PK/Dp3ef2WUEz//spy0jg8oKL31+lQ3ACKvvDaQl8C1qjqEwHlgW2LFwArc+9bEkSksohUyVnGdZqu5Migk3jPH/gRX4Cj/tILl/Pnye9cfQhc4V3F0gPYHdCMUGJEpB9wJzBQVfcGlMeJN3OmiDTFDSC6wYf48vsuPwSGips+uglBDnAaAmcBa1U1JafAj3OX328JxfXvryR79cPtgbtq4Edc9r/b51hOw1UXlwNLvce5wOvACq/8Q6CeT/E1xV2hsgxYlXO+cJNmfQmsA74Aavh4DivjhtavFlDmy/nDJa4tQCaujfjq/M4V7qqVZ7x/hyuARJ/iW49r28759/cfb9uLvO98KbAEON+n+PL9LoG7vfP3A9C/pGPzyicD1+fa1o9zl99vSbH8+7NhRIwxxgStLDdPGWOMOUaWNIwxxgTNkoYxxpigWdIwxhgTNEsaxhhjgmZJw5hCiMghOXoE3WIbEdkbBdXPe0eMOSYhnSPcmFJin6om+B2EMeHAahrGHCdv3oTHxM0x8p2INPfK40XkK29gvS9FpLFXXkfcPBXLvMep3qEiROQFb+6DmSJS0dv+Zm9OhOUiMsWnj2nMUSxpGFO4irmapy4NWLdbVdsDTwMTvLJ/A6+qagfcoH8TvfKJwNeq2hE3H8Mqr7wF8Iyqngzswt1FDG7Og07eca4P1Ycz5ljYHeHGFEJE9qhqTB7lycAZqrrBGyDuN1WtKSLbcUNcZHrlW1S1loikAg1V9UDAMeKBz1W1hff6LiBKVf8pIp8Ce4BpwDRV3RPij2pMoaymYUzRaD7Lx+JAwPIhjvQ1nocbE6gzsMgbRdUYX1nSMKZoLg14/sZbXoAbNRngMmCut/wlMApARCJEpFp+BxWRckAjVZ0F3AVUA/5Q2zGmpNlfLsYUrqKILA14/amq5lx2W11EluNqC8O8sr8Ar4jIHUAqcJVXfgswSUSuxtUoRuFGS81LBPBfL7EIMFFVdxXbJzLmOFmfhjHHyevTSFTV7X7HYkxJseYpY4wxQbOahjHGmKBZTcMYY0zQLGkYY4wJmiUNY4wxQbOkYYwxJmiWNIwxxgTt/wEBuDhUw30k2QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl-LMG9Irmf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d2b9b8-c5f1-4753-b707-2d330f850d6e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# see how the model did!\n",
        "preds = model.predict(X)\n",
        "print(preds.shape)\n",
        "\n",
        "# i'm spreading that prediction across three nodes and they sum to 1\n",
        "print(preds[0])\n",
        "\n",
        "# sum it up! see how probability mass (1) is spread over three preds?\n",
        "np.sum(preds[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 3)\n",
            "[9.9960560e-01 3.9446677e-04 1.9940734e-09]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here is dummy_y\n",
        "dummy_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfuZZs9URWFD",
        "outputId": "e6a3c433-1934-4c44-e6fb-43182ee82fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here is what argmax does\n",
        "dummy_y.argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEuBSuRIRN8r",
        "outputId": "1b448192-c806-4311-eec0-dad914e641e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2,\n",
              "       0, 1, 0, 0, 1, 0, 2, 2, 0, 1, 2, 0, 2, 0, 1, 2, 0, 0, 0, 2, 0, 0,\n",
              "       0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 2, 2, 2, 1, 0, 1, 0, 1, 1, 1, 2,\n",
              "       0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 0, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 2,\n",
              "       0, 0, 2, 0, 1, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 2, 1, 0, 0, 2, 1,\n",
              "       2, 1, 2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 0, 0, 1, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "JNMpGytZRjim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax(axis=1)"
      ],
      "metadata": {
        "id": "vFv2FDCmRS0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE4cDc79syFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c1d9c8-0b6f-4624-e370-c5da9b34c34f"
      },
      "source": [
        "# here it is! almost a perfect prediction\n",
        "# actual is left, predicted is top\n",
        "# names can be found by inspecting Y\n",
        "matrix = confusion_matrix(dummy_y.argmax(axis=1), preds.argmax(axis=1))\n",
        "matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50,  0,  0],\n",
              "       [ 0, 47,  3],\n",
              "       [ 0,  0, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2we6Zkisru8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0795cee-641e-4772-c065-7c91f39bde1e"
      },
      "source": [
        "# more detail on how well things were predicted\n",
        "print(classification_report(dummy_y.argmax(axis=1), preds.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      0.94      0.97        50\n",
            "           2       0.94      1.00      0.97        50\n",
            "\n",
            "    accuracy                           0.98       150\n",
            "   macro avg       0.98      0.98      0.98       150\n",
            "weighted avg       0.98      0.98      0.98       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On Your Own\n",
        "Like I say at the end of the video - your job as a data scientist is to help people believe in your model. You need to make sure folks don't doubt your work!\n",
        "\n",
        "You should update this script to have a train_test_split where 30% of the data is used for testing. Don't forget to use a random seed.\n",
        "\n",
        "Then, train your model on X_train and y_train with a val_split equal to 0.2 and shuffle = True. When you do this, a chunk of the training partition is being used as a feedback signal to ensure your model isn't overfitting and generalizes to unseen data.\n",
        "\n",
        "As a further quality check, you then APPLY this fitted model to the test data via `model.predict(X_test)` and check to see that you get the same error metrics. This is the way to do it for any type of DL project!"
      ],
      "metadata": {
        "id": "LpzD6S8JScAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other key take-aways\n",
        "* Note that you had to use a LabelEncoder() here and that it sorted the categories in alphabetical order and then encoded them inplace with 0, 1, 2\n",
        "* You had to make dummy variables for Y (and you didn't need to do this for binary classification problems - this is because in binary classification you had 2 categories and one output node with a SIGMOID activation function which made predictions between 0 and 1).\n",
        "* The output node of your neural network had 3 nodes - why? Because you have three types of flowers that you are trying to predict. Note that you are using a softmax instead of a sigmoid activation function.\n",
        "  * You also are using `categorical_crossentropy` to split the predicted probability mass among your N categories."
      ],
      "metadata": {
        "id": "gHAWsqJVTKqk"
      }
    }
  ]
}