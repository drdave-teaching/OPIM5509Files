{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/drdave-teaching/OPIM5509Files/blob/main/OPIM5509_Module4_Files/Advanced_RNN_Theory.ipynb)"
      ],
      "metadata": {
        "id": "QmcI3lsz7tRR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPO-rGJ5BdsS"
      },
      "source": [
        "# Advanced RNN Theory\n",
        "**Dr. Dave Wanik - University of Connecticut**\n",
        "\n",
        "----------------------------\n",
        "\n",
        "\n",
        "**Convolution and Pooling (1D - for sequences!)**\n",
        "Pay attention to how the output shape changes when you include convolution and pooling.\n",
        "\n",
        "The rows become fewer (due to the convolutions/when the kernel hits the wall) and the columns become your number of 'feature maps'. Convolution does elementwise multiplication and summing, so your original shape of the input features (i.e. 9 stocks) gets destroyed. See below.\n",
        "\n",
        "For pooling, if you have any remainders - they simply get chopped out. So try to pick a kernel that prevents this, or include some padding (add 0s to help maintain shape and retain all information)\n",
        "\n",
        "**Recurrent Dropout vs. Dropout**\n",
        "Recurrent dropout occurs within a SimpleRNN, LSTM or GRU layer. It is DIFFERENT than a DROPOUT layer.\n",
        "\n",
        "**Bidirectional Layers**\n",
        "Sequences can be read both forwards and backwards, and so this Bidirectional() layer wraps around SimpleRNN, LSTM or GRU and fits two models at the same time (takes twice as long to run). Yes, they can also be stacked!\n",
        "\n",
        "**Monster**\n",
        "Put all of these concepts together and explain the output shape and trainable parameters... good luck!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3BgzcX8Bsw5"
      },
      "source": [
        "# import modules\n",
        "# standard modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# RNN-specific modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, SimpleRNN, GRU, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N650Xe1hWL0h"
      },
      "source": [
        "# Intro to Convolution and Pooling (Sequences)\n",
        "\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-523434af0d21bb0b59454aa9563cc90b.webp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFP1RlbBWO3e"
      },
      "source": [
        "# it does not matter how many features you have - the convolution for a single\n",
        "# feature map will recode your 9 features into 1 via elementwise multiplication and summing\n",
        "\n",
        "# link: https://www.quora.com/What-does-it-mean-by-1D-convolutional-neural-network\n",
        "\n",
        "# there are more examples on text sequences, and I'll share these in future videos!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ddtR-5CmkY"
      },
      "source": [
        "# Single SimpleRNN with Conv1D and MaxPool1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AsiwZGQBb3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c98a98f-90c1-47ac-8f66-af2755236f47"
      },
      "source": [
        "# same as Excel Spreadsheet\n",
        "n_features = 9 # 9 stock prices (WMT, GOOG, NETF, GE, AMD...)\n",
        "n_steps = 21 # lookback 21 days\n",
        "\n",
        "# my data is 9 columns and 21 days long\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "# remember - convolution does elementwise multiplication and summation!\n",
        "model.add(Conv1D(filters=3, # these are the new columns that will be created (YOU GET TO PICK THIS!)\n",
        "                 kernel_size=2, # this dictates the size of the modified lookback (YOU GET TO PICK THIS!)\n",
        "                 input_shape=(n_steps,n_features))) # notice how input shape goes in first layer\n",
        "# you are just downsampling that 1D array\n",
        "model.add(MaxPooling1D(2)) # the output from pooling is still a sequence (but is richer and denser)\n",
        "# the new sequence we create will go into a SimpleRNN layer\n",
        "model.add(SimpleRNN(30, activation='relu'))\n",
        "# the output from this layer will be (None, 30) and we just return the last hidden state\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_31 (Conv1D)          (None, 20, 3)             57        \n",
            "                                                                 \n",
            " max_pooling1d_31 (MaxPoolin  (None, 10, 3)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " simple_rnn_15 (SimpleRNN)   (None, 30)                1020      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,108\n",
            "Trainable params: 1,108\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convolutional layer\n",
        "# 9 input columns get transformed into 1 output column\n",
        "# kernel width of 2\n",
        "# 21 - 2 + 1 = 20 (shape)\n",
        "# 1 is equal to the number of feature maps\n",
        "\n",
        "# elementwise mutliplication and summation\n",
        "# weights + biases\n",
        "9*2*1 + 1  # 9 = 9 col inputs * 2 = kernel width * 1 output feature maps + 1 (for bias on one feature maps/sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ6sViNNNJ6L",
        "outputId": "fa41b403-14fe-4a73-c91d-edcaa61d2deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simpleRNN trainable parms\n",
        "# g Ã— [h(h+i) + h]\n",
        "# 1 x [30(30+1)+30]\n",
        "1*(30*(30+1)+30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4HyW1LQQYUM",
        "outputId": "3c9c5746-97be-4e07-e0c3-5f49266247e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "960"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convolution layer\n",
        "# elementwise mutliplication and summation\n",
        "# weights + biases\n",
        "9*3*2 + 3 # 9 = 9 col inputs * 2 = kernel width * 3 output feature maps + 3 (for bias on 3 feature maps/sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1zD1-37NdB7",
        "outputId": "205c422b-6049-4ecf-d7b4-4ffe21b3757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0km4VLhmZYMu"
      },
      "source": [
        "# Intro to Recurrent Dropout\n",
        "Imagine some of the weights being turned off in each of the feed-forward network WITHIN the recurrent layer!\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2250/1*goJVQs-p9kgLODFNyhl9zA.gif)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg6tzcVLCrGu"
      },
      "source": [
        "# Single LSTM layer with Conv1D and MaxPool1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QinEhcqCtJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2348df04-eb82-4c0c-ec8e-2b01bb85cae9"
      },
      "source": [
        "# same as Excel Spreadsheet\n",
        "n_features = 9 # 9 stock prices\n",
        "n_steps = 21 # lookback\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "# remember - convolution does elementwise multiplication and pooling!\n",
        "model.add(Conv1D(filters=1,\n",
        "                 kernel_size=2,\n",
        "                 input_shape=(n_steps,n_features))) # notice how input shape goes in first layer\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(LSTM(30, activation='relu', recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_39 (Conv1D)          (None, 20, 1)             19        \n",
            "                                                                 \n",
            " max_pooling1d_39 (MaxPoolin  (None, 10, 1)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_56 (LSTM)              (None, 30)                3840      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,890\n",
            "Trainable params: 3,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMHPMuqBHZEu"
      },
      "source": [
        "# Multiple LSTM layers with Conv1D and MaxPool1D and Recurrent Dropout\n",
        "recurrent_dropout=True as an argument in an LSTM layer is different than a Dropout() layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6roRE9QHb5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a42cb8-db02-4df0-d76c-b03b3cd671ff"
      },
      "source": [
        "# same as Excel Spreadsheet\n",
        "n_features = 9 # 9 stock prices\n",
        "n_steps = 21 # lookback\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "# remember - convolution does elementwise multiplication and pooling!\n",
        "model.add(Conv1D(filters=1, kernel_size=2, input_shape=(n_steps,n_features))) # notice how input shape goes in first layer\n",
        "model.add(MaxPooling1D(2))\n",
        "# return_sequences is only true for the recurrent layers going INTO other recurrent layers\n",
        "model.add(LSTM(30, activation='relu', recurrent_dropout=0.1, return_sequences=True))\n",
        "model.add(LSTM(40, activation='relu', recurrent_dropout=0.1, return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', recurrent_dropout=0.1, return_sequences=True))\n",
        "model.add(LSTM(60, activation='relu', recurrent_dropout=0.1))\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_33 (Conv1D)          (None, 20, 1)             19        \n",
            "                                                                 \n",
            " max_pooling1d_33 (MaxPoolin  (None, 10, 1)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_45 (LSTM)              (None, 10, 30)            3840      \n",
            "                                                                 \n",
            " lstm_46 (LSTM)              (None, 10, 40)            11360     \n",
            "                                                                 \n",
            " lstm_47 (LSTM)              (None, 10, 50)            18200     \n",
            "                                                                 \n",
            " lstm_48 (LSTM)              (None, 60)                26640     \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 60)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 61        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,120\n",
            "Trainable params: 60,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMVoHxFXCvv4"
      },
      "source": [
        "# Monster #1\n",
        "(stacked Conv1D and Pool1D layers, with recurrent_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAz2Vp60CxF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf683cb1-14c4-4650-97f7-e87ceb1e2fe7"
      },
      "source": [
        "# same as Excel Spreadsheet\n",
        "n_features = 20 # 20 stock prices\n",
        "n_steps = 50 # lookback\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "# remember - convolution does elementwise multiplication and pooling!\n",
        "model.add(Conv1D(filters=64, kernel_size=2, input_shape=(n_steps,n_features))) # notice how input shape goes in first layer\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(filters=128, kernel_size=2)) # no need for input shape!\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(SimpleRNN(64, activation='relu', return_sequences=True))\n",
        "model.add(SimpleRNN(120, activation='relu',\n",
        "                    recurrent_dropout=0.1))\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_34 (Conv1D)          (None, 49, 64)            2624      \n",
            "                                                                 \n",
            " max_pooling1d_34 (MaxPoolin  (None, 24, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_35 (Conv1D)          (None, 23, 128)           16512     \n",
            "                                                                 \n",
            " max_pooling1d_35 (MaxPoolin  (None, 11, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " simple_rnn_16 (SimpleRNN)   (None, 11, 64)            12352     \n",
            "                                                                 \n",
            " simple_rnn_17 (SimpleRNN)   (None, 120)               22200     \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 121       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,809\n",
            "Trainable params: 53,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZEzR5j2WxVY"
      },
      "source": [
        "# Introduction to Bidirectional Layers\n",
        "See Google Sheets for overview."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yn3aZ6LEyRk"
      },
      "source": [
        "# Single Bidirectional LSTM Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zdxIBCGE26H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a2616f-a43a-4838-b4bb-0b985b4f2968"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "# same as Excel Spreadsheet\n",
        "n_features = 9 # 9 stock prices\n",
        "n_steps = 21 # lookback\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(30, activation='relu'),\n",
        "                        input_shape=(n_steps,n_features)))\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()\n",
        "\n",
        "# if you ever get an error like 'the model has not yet been built'\n",
        "# it means that you have not provided an input shape to your model,\n",
        "# note how input is an argument to the Bidirectional layer, NOT the LSTM!\n",
        "# g*(h*(h+i)+h) # for a regular recurrent layer\n",
        "# 2*g*h(h+i)+h)\n",
        "# 4*(30*(30+9)+30) for a LSTM with 30 hidden size\n",
        "# 2*4*(30*(30+9)+30) for a LSTM with 30 hidden size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_24 (Bidirecti  (None, 60)               9600      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 60)                0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 61        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,661\n",
            "Trainable params: 9,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS7RW0n0FTq-"
      },
      "source": [
        "# Stacked Bidirectional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXZSMKOuFYeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09213a54-f4a9-4c75-ed85-306d3daaf983"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "# same as Excel Spreadsheet\n",
        "n_features = 9 # 9 stock prices\n",
        "n_steps = 21 # lookback\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(30, activation='relu', return_sequences=True),\n",
        "                        input_shape=(n_steps,n_features)))\n",
        "model.add(Bidirectional(LSTM(10, activation='relu')))\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_25 (Bidirecti  (None, 21, 60)           9600      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_26 (Bidirecti  (None, 20)               5680      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,301\n",
            "Trainable params: 15,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aNhcZwXF98v"
      },
      "source": [
        "# Monster #2\n",
        "Convolution, pooling, bidirectional etc. All of it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5ul9zLdGDc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2381f5c-252d-4025-9c54-7e43b4da3e4d"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "# same as Excel Spreadsheet\n",
        "n_features = 50 # 50 stock prices\n",
        "n_steps = 21 # lookback\n",
        "\n",
        "# for Conv1D, you can play with the filters and kernel size\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=20, kernel_size=2, input_shape=(n_steps,n_features))) # notice how input shape goes in first layer\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(filters=10, kernel_size=2,))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Bidirectional(LSTM(30, activation='relu', return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(60, activation='relu', return_sequences=True)))\n",
        "model.add(GRU(40, activation='relu', return_sequences=True))\n",
        "model.add(Bidirectional(LSTM(10, activation='relu')))\n",
        "model.add(Dropout(0.1)) # pick a number between 0.1 and 0.3\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_36 (Conv1D)          (None, 20, 20)            2020      \n",
            "                                                                 \n",
            " max_pooling1d_36 (MaxPoolin  (None, 10, 20)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_37 (Conv1D)          (None, 9, 10)             410       \n",
            "                                                                 \n",
            " max_pooling1d_37 (MaxPoolin  (None, 4, 10)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_27 (Bidirecti  (None, 4, 60)            9840      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_28 (Bidirecti  (None, 4, 120)           58080     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 4, 40)             19440     \n",
            "                                                                 \n",
            " bidirectional_29 (Bidirecti  (None, 20)               4080      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,891\n",
            "Trainable params: 93,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}