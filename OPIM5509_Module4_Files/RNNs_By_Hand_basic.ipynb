{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/drdave-teaching/OPIM5509Files/blob/main/OPIM5509_Module4_Files/RNNs_By_Hand_basic.ipynb)"
      ],
      "metadata": {
        "id": "APSOseqpT2Jd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ6NP5taEH40"
      },
      "source": [
        "# RNNs by Hand\n",
        "--------------------------------\n",
        "**Dr. Dave Wanik - University of Connecticut**\n",
        "Being able to count the trainable parameters by hand and describing the output shape of each layer will help you ensure that you actually know how these algorithms work. It will crystallize why you need to prep your data as 3D tensors.\n",
        "\n",
        "Here's a cheat sheat for counting parms in deep learning models:\n",
        "* **Link:** https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889\n",
        "\n",
        "And here's the blog with animated RNN, LSTM and GRU\n",
        "* **Link:** https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxXYedi70C4o"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, SimpleRNN, LSTM, GRU, Conv2D\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDA7C9HyIsil"
      },
      "source": [
        "# Dense Neural Networks\n",
        "(or feed-forward neural networks, FFNN)\n",
        "\n",
        "* i, input size\n",
        "* h, size of hidden layer\n",
        "* o, output size\n",
        "For one hidden layer,\n",
        "\n",
        "```\n",
        "num_params\n",
        "= connections between layers + biases in every layer\n",
        "= (i×h + h×o) + (h+o)\n",
        "```\n",
        "\n",
        "The example on the webpage assumes you have an input, a hidden layer and an output. For our examples with RNNs, we will assume o=0, and just use i and h. See below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjHRkXVYx50M"
      },
      "source": [
        "### One Simple RNN\n",
        "One simpleRNN layer followed by a dense layer.\n",
        "\n",
        "* `g`, no. of FFNNs in a unit (RNN has 1, GRU has 3, LSTM has 4)\n",
        "* `h`, size of hidden units\n",
        "* `i`, dimension/size of input\n",
        "\n",
        "Since every FFNN (DNN) has `h(h+i) + h` parameters, we have\n",
        "num_params = `g × [h(h+i) + h]`\n",
        "\n",
        "Recall that the SimpleRNN only has one 'gate' or FFNN (you can see this in the cell!)\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1928/1*xn5kA92_J5KLaKcP7BMRLA.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJd33IglP19i"
      },
      "source": [
        "## One Simple RNN Layer (basic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuxawD1jZqHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31367f5-44ff-4277-cec0-addca538366e"
      },
      "source": [
        "# here's the script for the image above\n",
        "\n",
        "# for an SimpleRNN, the input shape is \"input_shape=(n_steps, n_features)\"\n",
        "# this corresponds to the graph in \"Animated!\"\n",
        "n_steps=50 # doesn't matter!\n",
        "n_features=3 # the 3 green dots... APPL, GOOGLE, FB\n",
        "model = Sequential()\n",
        "# parms in SimpleRNN is\n",
        "model.add((SimpleRNN(2, activation='relu', input_shape=(n_steps, n_features)))) # the two red dots\n",
        "\n",
        "# it is those 2 red dots that will go into the dense layer (don't forget to add 1 for the bias!)\n",
        "model.add(Dense(1)) # this dense layer is not show in the animation, but it's needed! # predict netflix!\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15\n",
            "Trainable params: 15\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfGHoj-NP8Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d019223-52f8-4340-a6ec-a9a32eddee7c"
      },
      "source": [
        "# try the math\n",
        "# for each layer\n",
        "\n",
        "\n",
        "# TRAINABLE PARAMETERS\n",
        "# the general RNN layer formula is g × [h(h+i) + h]\n",
        "g = 1 # there's only 1 FFNN in a simpleRNN cell (look above!)\n",
        "h = 2\n",
        "i = 3 # this is number of features, not the lookback!\n",
        "print(g*(h*(h+i) + h))\n",
        "\n",
        "# SHAPE\n",
        "# (None, 2) where 2 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 2 going into a dense layer\n",
        "# this is what the 2 in simpleRNN(2) means! just 2 red dots.\n",
        "\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has a 1\n",
        "i = 2 # 2 hidden node inputs\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o))\n",
        "\n",
        "# output shape is (NONE,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjpKuMxXPuUL"
      },
      "source": [
        "## One Simple RNN Layer (advanced)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTSfmUz7wkHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c0383f-a511-422a-f597-5846334a6dfc"
      },
      "source": [
        "# here's a related quiz question\n",
        "\n",
        "# for an SimpleRNN, the input shape is \"input_shape=(n_steps, n_features)\"\n",
        "# this corresponds to the graph in \"Animated!\"\n",
        "n_steps=50\n",
        "n_features=30 # having 30 stocks for covariates\n",
        "model = Sequential()\n",
        "model.add((SimpleRNN(25, activation='relu', input_shape=(n_steps, n_features))))\n",
        "# it is those 25 red dots going into the dense layer, so you need 26 parms\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_3 (SimpleRNN)    (None, 25)                1400      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,426\n",
            "Trainable params: 1,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSnavs4CES01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae88250-8642-4fee-faa0-0f8069fc41b1"
      },
      "source": [
        "# try the math\n",
        "# for each layer\n",
        "\n",
        "\n",
        "# TRAINABLE PARAMETERS\n",
        "# the general RNN layer formula is g × [h(h+i) + h]\n",
        "g = 1\n",
        "h = 25\n",
        "i = 30 # this is number of features, not the lookback!\n",
        "print(g*(h*(h+i) + h)) #answer = 1400\n",
        "\n",
        "# SHAPE\n",
        "# (None, 25) where 25 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 25 going into a dense layer\n",
        "# this is what the 25 in simpleRNN(25) means! just 25 red dots.\n",
        "\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has a 1\n",
        "i = 25\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o)) #answer = 26\n",
        "\n",
        "# output shape is (NONE,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400\n",
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Af2OuNxyAvy"
      },
      "source": [
        "## One LSTM Layer (basic)\n",
        "Here is what an LSTM looks like. Recall that it has four 'gates' or FFNNs.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2250/1*goJVQs-p9kgLODFNyhl9zA.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8wBPicQa_-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a160ec69-bf51-4130-a9bf-04d3dbef9b69"
      },
      "source": [
        "# here is the code that corresponds to the image\n",
        "\n",
        "# for an LSTM, the input shape is \"input_shape=(n_steps, n_features)\"\n",
        "# same example as above, just presented a different way\n",
        "n_steps= 50 # doesn't matter! it will loop.\n",
        "n_features= 3 # these are the 3 green dots\n",
        "model = Sequential()\n",
        "model.add((LSTM(2,  # these are the 2 red dots\n",
        "                activation='relu', input_shape=(n_steps, n_features))))\n",
        "model.add(Dense(1)) # not shown, but you need it and should realize that the\n",
        "                    # 2 dark red dots are what will go into the dense layer\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 2)                 48        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvFPEdSzQMvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de70651-bfbb-4c67-974d-08f36e563911"
      },
      "source": [
        "# try the math\n",
        "\n",
        "# simple RNN\n",
        "# TRAINABLE PARAMETERS\n",
        "# the generic RNN layer is g × [h(h+i) + h]\n",
        "g = 4 #LSTM has 4 FFNNs!\n",
        "h = 2 # hidden units within LSTM, the two red dots\n",
        "i = 3 # this is number of features, not the lookback! these are your 3 stocks (green dots!)\n",
        "print(g*(h*(h+i) + h))\n",
        "\n",
        "# SHAPE\n",
        "# (None, 2) where 2 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 2 going into a dense layer\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has 1 output\n",
        "i = 2 # these are all 4 inputs going into a dense layer\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1p66gxkQGJ8"
      },
      "source": [
        "## One LSTM Layer (advanced)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FTZ_j9pyHvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205d7379-e2ac-4adb-96c7-5591794ad156"
      },
      "source": [
        "# for an LSTM, the input shape is \"input_shape=(n_steps, n_features)\"\n",
        "# same example as above, just presented a different way\n",
        "n_steps= 30 # lookback\n",
        "n_features= 5 # 5 different stocks, 5 green dots\n",
        "model = Sequential()\n",
        "model.add((LSTM(4, activation='relu', input_shape=(n_steps, n_features)))) # hidden units = 4 means 4 red dots\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 4)                 160       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 165\n",
            "Trainable params: 165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qWUeqMEKDCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe5a4ac-6a4e-45e3-b23f-9ae099e02d6e"
      },
      "source": [
        "# try the math\n",
        "\n",
        "# TRAINABLE PARAMETERS\n",
        "# the generic RNN forumla is g × [h(h+i) + h]\n",
        "g = 4 #LSTM has 4! these are the 4 FFNNs\n",
        "h = 4 # hidden units within LSTM (you get to decide this! it's the red dots...)\n",
        "i = 5 # this is number of features, not the lookback! the green dots... your 5 stocks\n",
        "print(g*(h*(h+i) + h)) #answer = 160\n",
        "\n",
        "# SHAPE\n",
        "# (None, 4) where 4 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 4 going into a dense layer\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has a 1\n",
        "i = 4 # these are all 4 inputs going into a dense layer\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o)) #answer = 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOSpOZQ9yJs0"
      },
      "source": [
        "## One GRU Layer (basic)\n",
        "This is what a GRU looks like - note that it has three 'gates'.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2214/1*lNNJOWnMjxLzdUnUQqwKcw.gif)\n",
        "\n",
        "Caution: TensorFlow version difference!\n",
        "Link: https://stackoverflow.com/questions/57318930/calculating-the-number-of-parameters-of-a-gru-layer-keras\n",
        "\n",
        "Be careful of the bias term! Otherwise you need to add"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4226G-0Qcd94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1863918e-b779-48d9-9566-daef429cbe13"
      },
      "source": [
        "# here is the example from the image\n",
        "# and here is a related example\n",
        "n_steps=50 # doesn't matter\n",
        "n_features=3 # three stocks (FB, APPL, GOOG), three green dots\n",
        "model = Sequential()\n",
        "model.add((GRU(2, activation='relu', input_shape=(n_steps, n_features), # 2 red dots\n",
        "               reset_after=False)))  # try this as False - helps math work out\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "# if you don't say reset_after = False, you should add the bias terms\n",
        "# which are bias_shape = (2, 3 * self.units)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_3 (GRU)                 (None, 2)                 36        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39\n",
            "Trainable params: 39\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTZLI_ZtefcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cf29eb-c19c-41f4-8857-f2e52f14f95b"
      },
      "source": [
        "# here is the math for that example\n",
        "# try the math\n",
        "\n",
        "# gru\n",
        "# TRAINABLE PARAMETERS\n",
        "# the general RNN layer is g × [h(h+i) + h]\n",
        "g = 3 #GRU has 3 FFNNs (this is ALWAYS TRUE for GRU)\n",
        "h = 2 # hidden units within GRU (RED DOTS)\n",
        "i = 3 # this is number of features, not the lookback! (GREEN DOTS)\n",
        "print('# of trainable parms in gru_1 = ', g*(h*(h+i) + h))\n",
        "\n",
        "# SHAPE\n",
        "# (None, 2) where 2 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 2 going into a dense layer\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has a 1\n",
        "i = 2 # these are all 2 inputs going into a dense layer\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of trainable parms in gru_1 =  36\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0vPONFKIYRK"
      },
      "source": [
        "## One GRU Layer (advanced)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLEnRce5yL5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdb4d9a-7a56-45d0-c8b0-288888351853"
      },
      "source": [
        "# and here is a related example\n",
        "n_steps=30000000 # so many time steps!\n",
        "n_features=5 # five stocks = five green dots = FB, GOOG, APPL, GE, AMD\n",
        "model = Sequential()\n",
        "model.add((GRU(4, activation='relu', input_shape=(n_steps, n_features), # 4 red dots\n",
        "               reset_after=False)))  # try this as False for no extra bias\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "# if you don't say reset_after = False, you should add the bias terms\n",
        "# which are bias_shape = (2, 3 * self.units)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_4 (GRU)                 (None, 4)                 120       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 125\n",
            "Trainable params: 125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfCgO0PqK___",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d10fef-2fed-438d-a725-de16d0c36276"
      },
      "source": [
        "# try the math\n",
        "\n",
        "# gru\n",
        "# TRAINABLE PARAMETERS\n",
        "# the general RNN layer is g × [h(h+i) + h]\n",
        "g = 3 #GRU has 3!\n",
        "h = 4 # hidden units within GRU\n",
        "i = 5 # this is number of features, not the lookback!\n",
        "print('# of trainable parms in gru_1 = ', g*(h*(h+i) + h))\n",
        "print(g*(h*(h+i) + h))\n",
        "\n",
        "# SHAPE\n",
        "# (None, 4) where 4 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 4 going into a dense layer\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has a 1\n",
        "i = 4 # these are all 4 inputs going into a dense layer\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of trainable parms in gru_1 =  120\n",
            "120\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWoG7RrsIea7"
      },
      "source": [
        "# Advanced (stacking, mixing and matching.)\n",
        "We will cover this in future lectures - provided as FYI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALaPWo_pyMa3"
      },
      "source": [
        "### Two GRU layers going into a SimpleRNN\n",
        "This is the fun part! Since you are returning sequences - the output shape will be 3D... you are storing all outputs from the DNNs within each GRU layer!\n",
        "\n",
        "This is where n_steps actually gets used in the output size. Don't forget to set `return_sequences=True` when stacking layers - except for the last one that goes into the Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XvyPVP-ydPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d594ab-c5f8-4b3c-bc5b-979b00bf153f"
      },
      "source": [
        "n_steps=30 # this matters for output shape when we return sequences!\n",
        "n_features=5 # these are 5 stocks (FB, APPL, GE, NETFLIX, AMD)\n",
        "\n",
        "model = Sequential()\n",
        "model.add((GRU(4, return_sequences=True, activation='relu', input_shape=(n_steps, n_features))))\n",
        "model.add((GRU(2, return_sequences=True, activation='relu')))\n",
        "model.add((SimpleRNN(25, activation='relu')))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_5 (GRU)                 (None, 30, 4)             132       \n",
            "                                                                 \n",
            " gru_6 (GRU)                 (None, 30, 2)             48        \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 25)                700       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt5ycxLMMmPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa82307-f0df-4c1f-bd85-89fed8a359ad"
      },
      "source": [
        "# try the math\n",
        "\n",
        "# gru_1\n",
        "# TRAINABLE PARAMETERS\n",
        "# the general RNN layer formula is g × [h(h+i) + h]\n",
        "g = 3 #GRU has 3!\n",
        "h = 4 # hidden units within GRU\n",
        "i = 5 # this is number of features, not the lookback!\n",
        "print(g*(h*(h+i) + h)) #answer = 132\n",
        "\n",
        "# SHAPE\n",
        "# (None, 30, 4) where:\n",
        "# 30 is the number of time steps (yes, it's appeared now!)\n",
        "# 4 are the number of hidden units\n",
        "# so the time series is now a derivative time series - it's a time series of\n",
        "# dark red dots from the animation!\n",
        "\n",
        "# gru_2\n",
        "# TRAINABLE PARAMETERS\n",
        "# the general RNN layer is g × [h(h+i) + h]\n",
        "g = 3 #GRU has 3!\n",
        "h = 2 # hidden units within GRU (we get to choose this)\n",
        "i = 4 # this is number of features, not the lookback! this is inherited from previous layer\n",
        "print(g*(h*(h+i) + h)) #answer = 132\n",
        "\n",
        "# SHAPE\n",
        "# (None, 4) where 4 are the number of hidden units\n",
        "# so the time series is now just a flattened input of 4 going into a dense layer\n",
        "\n",
        "\n",
        "# dense layer\n",
        "# TRAINABLE PARAMETERS\n",
        "# the dense layer is (i×h + h×o) + (h+o)\n",
        "# but we ignore h since there is not output\n",
        "h = 1 # the dense layer has a 1\n",
        "i = 4 # these are all 4 inputs going into a dense layer\n",
        "o = 0 # there is no output\n",
        "print((i*h + h*o) + (h+o)) #answer = 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n",
            "42\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwq20CPTydqq"
      },
      "source": [
        "### One SimpleRNN going into an LSTM\n",
        "Left to students as an exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwhdhwo8ylZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d83561-6ea4-42c4-fe46-68f32e3a5d5a"
      },
      "source": [
        "n_steps=15 # lookback\n",
        "n_features=30 # 30 different stocks\n",
        "\n",
        "model = Sequential()\n",
        "model.add((SimpleRNN(20, return_sequences=True, activation='relu', input_shape=(n_steps, n_features))))\n",
        "model.add((LSTM(4, activation='relu'))) # see how there is NO RETURN SEQUENCES!!!\n",
        "model.add(Dense(1))                             # you just keep the last hidden state\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_5 (SimpleRNN)    (None, 15, 20)            1020      \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 4)                 400       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,425\n",
            "Trainable params: 1,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4q4MWdWrjqv"
      },
      "source": [
        "### Monster #1\n",
        "Left as an exercise for students."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd2mEpzxrmsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c13a59-26c5-4c36-ff95-09f2cbfeb713"
      },
      "source": [
        "n_steps=30\n",
        "n_features=30\n",
        "model = Sequential()\n",
        "model.add((SimpleRNN(30, return_sequences=True, activation='relu', input_shape=(n_steps, n_features))))\n",
        "model.add((GRU(30, return_sequences=True,activation='relu')))\n",
        "model.add((LSTM(30,activation='relu')))\n",
        "model.add((Dense(30,activation='relu')))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_6 (SimpleRNN)    (None, 30, 30)            1830      \n",
            "                                                                 \n",
            " gru_7 (GRU)                 (None, 30, 30)            5580      \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 30)                7320      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,691\n",
            "Trainable params: 15,691\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLn57U1bsEFG"
      },
      "source": [
        "### Monster #2\n",
        "Left as an exercise for students."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzTdueSfsC3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85021dec-42eb-4a6f-8c0a-9ffeb616098e"
      },
      "source": [
        "n_steps=50\n",
        "n_features=40\n",
        "model = Sequential()\n",
        "model.add((SimpleRNN(30, return_sequences=True, activation='relu', input_shape=(n_steps, n_features))))\n",
        "model.add((GRU(20, return_sequences=True,activation='relu')))\n",
        "model.add((GRU(25, return_sequences=True,activation='relu')))\n",
        "model.add((GRU(22, return_sequences=True,activation='relu')))\n",
        "model.add((GRU(21, return_sequences=True,activation='relu')))\n",
        "model.add((SimpleRNN(10,activation='relu')))\n",
        "model.add((Dense(50,activation='relu')))\n",
        "model.add((Dense(50,activation='relu')))\n",
        "model.add((Dense(50,activation='relu')))\n",
        "model.add((Dense(50,activation='relu')))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_7 (SimpleRNN)    (None, 50, 30)            2130      \n",
            "                                                                 \n",
            " gru_8 (GRU)                 (None, 50, 20)            3120      \n",
            "                                                                 \n",
            " gru_9 (GRU)                 (None, 50, 25)            3525      \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 50, 22)            3234      \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 50, 21)            2835      \n",
            "                                                                 \n",
            " simple_rnn_8 (SimpleRNN)    (None, 10)                320       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 50)                550       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,415\n",
            "Trainable params: 23,415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}